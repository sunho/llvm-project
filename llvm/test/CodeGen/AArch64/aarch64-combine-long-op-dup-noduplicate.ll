; NOTE: Assertions have been autogenerated by utils/update_llc_test_checks.py
; RUN: llc < %s -asm-verbose=0 -mtriple=aarch64-linux-gnu -mattr=+neon | FileCheck %s
; When high version and low version of long operation (e.g. umull, sabdl)
; use the same vdup vector, vdup vector is extended for high version and this extended
; vector should be reused in low version to have no duplicate vdup.
;

define <8 x i16> @test_umull_combine_constant(<16 x i8> %x) {
; CHECK-LABEL: test_umull_combine_constant:
; CHECK:         movi v2.16b, #33
; CHECK-NEXT:    umull v1.8h, v0.8b, v2.8b
; CHECK-NEXT:    umlal2 v1.8h, v0.16b, v2.16b
; CHECK-NEXT:    mov v0.16b, v1.16b
; CHECK-NEXT:    ret
entry:
  %lowx = shufflevector <16 x i8> %x, <16 x i8> poison, <8 x i32> <i32 0, i32 1, i32 2, i32 3, i32 4, i32 5, i32 6, i32 7>
  %mul1 = tail call <8 x i16> @llvm.aarch64.neon.umull.v8i16(<8 x i8> %lowx, <8 x i8> <i8 33, i8 33, i8 33, i8 33, i8 33, i8 33, i8 33, i8 33>)
  %highx = shufflevector <16 x i8> %x, <16 x i8> poison, <8 x i32> <i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15>
  %mul2 = tail call <8 x i16> @llvm.aarch64.neon.umull.v8i16(<8 x i8> %highx, <8 x i8> <i8 33, i8 33, i8 33, i8 33, i8 33, i8 33, i8 33, i8 33>)
  %res = add <8 x i16> %mul1, %mul2
  ret <8 x i16> %res
}

define <8 x i16> @test_umull_combine_vdup(<16 x i8> %x, <16 x i8> %y, i8 %c) {
; CHECK-LABEL: test_umull_combine_vdup:
; CHECK:         dup v2.16b, w0
; CHECK-NEXT:    umull v1.8h, v0.8b, v2.8b
; CHECK-NEXT:    umlal2 v1.8h, v0.16b, v2.16b
; CHECK-NEXT:    mov v0.16b, v1.16b
; CHECK-NEXT:    ret
entry:
  %lowx = shufflevector <16 x i8> %x, <16 x i8> poison, <8 x i32> <i32 0, i32 1, i32 2, i32 3, i32 4, i32 5, i32 6, i32 7>
  %dup.i = insertelement <8 x i8> poison, i8 %c, i32 0
  %dup = shufflevector <8 x i8> %dup.i, <8 x i8> poison, <8 x i32> zeroinitializer
  %highx = shufflevector <16 x i8> %x, <16 x i8> poison, <8 x i32> <i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15>
  %mul1 = tail call <8 x i16> @llvm.aarch64.neon.umull.v8i16(<8 x i8> %lowx, <8 x i8> %dup)
  %mul2 = tail call <8 x i16> @llvm.aarch64.neon.umull.v8i16(<8 x i8> %highx, <8 x i8> %dup)
  %res = add <8 x i16> %mul1, %mul2
  ret <8 x i16> %res
}

define <8 x i16> @test_vabdl_combine_vdup(<16 x i8> %x, i8 %c) {
; CHECK-LABEL: test_vabdl_combine_vdup:
; CHECK:         dup v2.16b, w0
; CHECK-NEXT:    sabdl v1.8h, v0.8b, v2.8b
; CHECK-NEXT:    sabal2 v1.8h, v0.16b, v2.16b
; CHECK-NEXT:    mov v0.16b, v1.16b
; CHECK-NEXT:    ret
entry:
  %lowx = shufflevector <16 x i8> %x, <16 x i8> poison, <8 x i32> <i32 0, i32 1, i32 2, i32 3, i32 4, i32 5, i32 6, i32 7>
  %dup.i = insertelement <8 x i8> poison, i8 %c, i32 0
  %dup = shufflevector <8 x i8> %dup.i, <8 x i8> poison, <8 x i32> zeroinitializer
  %sabd1 = call <8 x i8> @llvm.aarch64.neon.sabd.v8i8(<8 x i8> %lowx, <8 x i8> %dup)
  %zext1 = zext <8 x i8> %sabd1 to <8 x i16>
  %highx = shufflevector <16 x i8> %x, <16 x i8> poison, <8 x i32> <i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15>
  %sabd2 = call <8 x i8> @llvm.aarch64.neon.sabd.v8i8(<8 x i8> %highx, <8 x i8> %dup)
  %zext2 = zext <8 x i8> %sabd2 to <8 x i16>
  %res = add <8 x i16> %zext1, %zext2
  ret <8 x i16> %res
}

define <8 x i16> @test_umull_combine_constant2(<16 x i8> %x, <16 x i8> %y) {
; CHECK-LABEL: test_umull_combine_constant2:
; CHECK:         movi v2.16b, #33
; CHECK-NEXT:    movi v3.16b, #119
; CHECK-NEXT:    umull v4.8h, v0.8b, v2.8b
; CHECK-NEXT:    umull2 v5.8h, v1.16b, v3.16b
; CHECK-NEXT:    umlsl v4.8h, v1.8b, v3.8b
; CHECK-NEXT:    umlsl2 v5.8h, v0.16b, v2.16b
; CHECK-NEXT:    add v0.8h, v4.8h, v5.8h
; CHECK-NEXT:    ret
entry:
  %lowx = shufflevector <16 x i8> %x, <16 x i8> poison, <8 x i32> <i32 0, i32 1, i32 2, i32 3, i32 4, i32 5, i32 6, i32 7>
  %mul1 = tail call <8 x i16> @llvm.aarch64.neon.umull.v8i16(<8 x i8> %lowx, <8 x i8> <i8 33, i8 33, i8 33, i8 33, i8 33, i8 33, i8 33, i8 33>)
  %lowy = shufflevector <16 x i8> %y, <16 x i8> poison, <8 x i32> <i32 0, i32 1, i32 2, i32 3, i32 4, i32 5, i32 6, i32 7>
  %mul2 = tail call <8 x i16> @llvm.aarch64.neon.umull.v8i16(<8 x i8> %lowy, <8 x i8> <i8 119, i8 119, i8 119, i8 119, i8 119, i8 119, i8 119, i8 119>)
  %sub1 = sub <8 x i16> %mul1, %mul2
  %highx = shufflevector <16 x i8> %x, <16 x i8> poison, <8 x i32> <i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15>
  %mul3 = tail call <8 x i16> @llvm.aarch64.neon.umull.v8i16(<8 x i8> %highx, <8 x i8> <i8 33, i8 33, i8 33, i8 33, i8 33, i8 33, i8 33, i8 33>)
  %highy = shufflevector <16 x i8> %y, <16 x i8> poison, <8 x i32> <i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15>
  %mul4 = tail call <8 x i16> @llvm.aarch64.neon.umull.v8i16(<8 x i8> %highy, <8 x i8> <i8 119, i8 119, i8 119, i8 119, i8 119, i8 119, i8 119, i8 119>)
  %sub2 = sub <8 x i16> %mul3, %mul4
  %res = sub <8 x i16> %sub1, %sub2
  ret <8 x i16> %res
}

define <8 x i16> @test_umull_combine_vdup2(<16 x i8> %x, <16 x i8> %y, <8 x i8> %coeffs) {
; CHECK-LABEL: test_umull_combine_vdup2:
; CHECK:         dup v3.16b, v2.b[0]
; CHECK-NEXT:    dup v2.16b, v2.b[1]
; CHECK-NEXT:    umull v4.8h, v0.8b, v3.8b
; CHECK-NEXT:    umull2 v5.8h, v1.16b, v2.16b
; CHECK-NEXT:    umlsl v4.8h, v1.8b, v2.8b
; CHECK-NEXT:    umlsl2 v5.8h, v0.16b, v3.16b
; CHECK-NEXT:    add v0.8h, v4.8h, v5.8h
; CHECK-NEXT:    ret
  %lowx = shufflevector <16 x i8> %x, <16 x i8> poison, <8 x i32> <i32 0, i32 1, i32 2, i32 3, i32 4, i32 5, i32 6, i32 7>
  %dup1 = shufflevector <8 x i8> %coeffs, <8 x i8> poison, <8 x i32> zeroinitializer
  %mul1 = tail call <8 x i16> @llvm.aarch64.neon.umull.v8i16(<8 x i8> %lowx, <8 x i8> %dup1)
  %dup2 = shufflevector <8 x i8> %coeffs, <8 x i8> poison, <8 x i32> <i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1>
  %lowy = shufflevector <16 x i8> %y, <16 x i8> poison, <8 x i32> <i32 0, i32 1, i32 2, i32 3, i32 4, i32 5, i32 6, i32 7>
  %mul2 = tail call <8 x i16> @llvm.aarch64.neon.umull.v8i16(<8 x i8> %lowy, <8 x i8> %dup2)
  %sub1 = sub <8 x i16> %mul1, %mul2
  %highx = shufflevector <16 x i8> %x, <16 x i8> poison, <8 x i32> <i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15>
  %mul3 = tail call <8 x i16> @llvm.aarch64.neon.umull.v8i16(<8 x i8> %highx, <8 x i8> %dup1)
  %highy = shufflevector <16 x i8> %y, <16 x i8> poison, <8 x i32> <i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15>
  %mul4 = tail call <8 x i16> @llvm.aarch64.neon.umull.v8i16(<8 x i8> %highy, <8 x i8> %dup2)
  %sub2 = sub <8 x i16> %mul3, %mul4
  %res = sub <8 x i16> %sub1, %sub2
  ret <8 x i16> %res
}


declare <8 x i16> @llvm.aarch64.neon.umull.v8i16(<8 x i8>, <8 x i8>)
declare <8 x i8> @llvm.aarch64.neon.sabd.v8i8(<8 x i8>, <8 x i8>)
