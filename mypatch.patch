diff --git a/clang/lib/Interpreter/IncrementalParser.cpp b/clang/lib/Interpreter/IncrementalParser.cpp
index 0f1ef3233a2a..178246ff30b0 100644
--- a/clang/lib/Interpreter/IncrementalParser.cpp
+++ b/clang/lib/Interpreter/IncrementalParser.cpp
@@ -1,302 +1,305 @@
 //===--------- IncrementalParser.cpp - Incremental Compilation  -----------===//
 //
 // Part of the LLVM Project, under the Apache License v2.0 with LLVM Exceptions.
 // See https://llvm.org/LICENSE.txt for license information.
 // SPDX-License-Identifier: Apache-2.0 WITH LLVM-exception
 //
 //===----------------------------------------------------------------------===//
 //
 // This file implements the class which performs incremental code compilation.
 //
 //===----------------------------------------------------------------------===//
 
 #include "IncrementalParser.h"
 
 #include "clang/AST/DeclContextInternals.h"
 #include "clang/CodeGen/BackendUtil.h"
 #include "clang/CodeGen/CodeGenAction.h"
 #include "clang/CodeGen/ModuleBuilder.h"
 #include "clang/Frontend/CompilerInstance.h"
 #include "clang/Frontend/FrontendAction.h"
 #include "clang/FrontendTool/Utils.h"
 #include "clang/Parse/Parser.h"
 #include "clang/Sema/Sema.h"
 
 #include "llvm/Option/ArgList.h"
 #include "llvm/Support/CrashRecoveryContext.h"
 #include "llvm/Support/Error.h"
 #include "llvm/Support/Timer.h"
 
 #include <sstream>
 
 namespace clang {
 
 /// A custom action enabling the incremental processing functionality.
 ///
 /// The usual \p FrontendAction expects one call to ExecuteAction and once it
 /// sees a call to \p EndSourceFile it deletes some of the important objects
 /// such as \p Preprocessor and \p Sema assuming no further input will come.
 ///
 /// \p IncrementalAction ensures it keep its underlying action's objects alive
 /// as long as the \p IncrementalParser needs them.
 ///
 class IncrementalAction : public WrapperFrontendAction {
 private:
   bool IsTerminating = false;
 
 public:
   IncrementalAction(CompilerInstance &CI, llvm::LLVMContext &LLVMCtx,
                     llvm::Error &Err)
       : WrapperFrontendAction([&]() {
           llvm::ErrorAsOutParameter EAO(&Err);
           std::unique_ptr<FrontendAction> Act;
           switch (CI.getFrontendOpts().ProgramAction) {
           default:
             Err = llvm::createStringError(
                 std::errc::state_not_recoverable,
                 "Driver initialization failed. "
                 "Incremental mode for action %d is not supported",
                 CI.getFrontendOpts().ProgramAction);
             return Act;
           case frontend::ASTDump:
             LLVM_FALLTHROUGH;
           case frontend::ASTPrint:
             LLVM_FALLTHROUGH;
           case frontend::ParseSyntaxOnly:
             Act = CreateFrontendAction(CI);
             break;
           case frontend::PluginAction:
             LLVM_FALLTHROUGH;
           case frontend::EmitAssembly:
             LLVM_FALLTHROUGH;
           case frontend::EmitObj:
             LLVM_FALLTHROUGH;
           case frontend::EmitLLVMOnly:
             Act.reset(new EmitLLVMOnlyAction(&LLVMCtx));
             break;
           }
           return Act;
         }()) {}
   FrontendAction *getWrapped() const { return WrappedAction.get(); }
   TranslationUnitKind getTranslationUnitKind() override {
     return TU_Incremental;
   }
   void ExecuteAction() override {
     CompilerInstance &CI = getCompilerInstance();
     assert(CI.hasPreprocessor() && "No PP!");
 
     // FIXME: Move the truncation aspect of this into Sema, we delayed this till
     // here so the source manager would be initialized.
     if (hasCodeCompletionSupport() &&
         !CI.getFrontendOpts().CodeCompletionAt.FileName.empty())
       CI.createCodeCompletionConsumer();
 
     // Use a code completion consumer?
     CodeCompleteConsumer *CompletionConsumer = nullptr;
     if (CI.hasCodeCompletionConsumer())
       CompletionConsumer = &CI.getCodeCompletionConsumer();
 
     Preprocessor &PP = CI.getPreprocessor();
     PP.enableIncrementalProcessing();
     PP.EnterMainSourceFile();
 
     if (!CI.hasSema())
       CI.createSema(getTranslationUnitKind(), CompletionConsumer);
   }
 
   // Do not terminate after processing the input. This allows us to keep various
   // clang objects alive and to incrementally grow the current TU.
   void EndSourceFile() override {
     // The WrappedAction can be nullptr if we issued an error in the ctor.
     if (IsTerminating && getWrapped())
       WrapperFrontendAction::EndSourceFile();
   }
 
   void FinalizeAction() {
     assert(!IsTerminating && "Already finalized!");
     IsTerminating = true;
     EndSourceFile();
   }
 };
 
 IncrementalParser::IncrementalParser(std::unique_ptr<CompilerInstance> Instance,
                                      llvm::LLVMContext &LLVMCtx,
                                      llvm::Error &Err)
     : CI(std::move(Instance)) {
   llvm::ErrorAsOutParameter EAO(&Err);
   Act = std::make_unique<IncrementalAction>(*CI, LLVMCtx, Err);
   if (Err)
     return;
   CI->ExecuteAction(*Act);
   Consumer = &CI->getASTConsumer();
   P.reset(
       new Parser(CI->getPreprocessor(), CI->getSema(), /*SkipBodies=*/false));
   P->Initialize();
 }
 
-IncrementalParser::~IncrementalParser() { Act->FinalizeAction(); }
+IncrementalParser::~IncrementalParser() {
+    P.reset();
+    Act->FinalizeAction(); 
+}
 
 llvm::Expected<PartialTranslationUnit &>
 IncrementalParser::ParseOrWrapTopLevelDecl() {
   // Recover resources if we crash before exiting this method.
   Sema &S = CI->getSema();
   llvm::CrashRecoveryContextCleanupRegistrar<Sema> CleanupSema(&S);
   Sema::GlobalEagerInstantiationScope GlobalInstantiations(S, /*Enabled=*/true);
   Sema::LocalEagerInstantiationScope LocalInstantiations(S);
 
   PTUs.emplace_back(PartialTranslationUnit());
   PartialTranslationUnit &LastPTU = PTUs.back();
   // Add a new PTU.
   ASTContext &C = S.getASTContext();
   C.addTranslationUnitDecl();
   LastPTU.TUPart = C.getTranslationUnitDecl();
 
   // Skip previous eof due to last incremental input.
   if (P->getCurToken().is(tok::eof)) {
     P->ConsumeToken();
     // FIXME: Clang does not call ExitScope on finalizing the regular TU, we
     // might want to do that around HandleEndOfTranslationUnit.
     P->ExitScope();
     S.CurContext = nullptr;
     // Start a new PTU.
     P->EnterScope(Scope::DeclScope);
     S.ActOnTranslationUnitScope(P->getCurScope());
   }
 
   Parser::DeclGroupPtrTy ADecl;
   Sema::ModuleImportState ImportState;
   for (bool AtEOF = P->ParseFirstTopLevelDecl(ADecl, ImportState); !AtEOF;
        AtEOF = P->ParseTopLevelDecl(ADecl, ImportState)) {
     // If we got a null return and something *was* parsed, ignore it.  This
     // is due to a top-level semicolon, an action override, or a parse error
     // skipping something.
     if (ADecl && !Consumer->HandleTopLevelDecl(ADecl.get()))
       return llvm::make_error<llvm::StringError>("Parsing failed. "
                                                  "The consumer rejected a decl",
                                                  std::error_code());
   }
 
   DiagnosticsEngine &Diags = getCI()->getDiagnostics();
   if (Diags.hasErrorOccurred()) {
     TranslationUnitDecl *MostRecentTU = C.getTranslationUnitDecl();
     TranslationUnitDecl *PreviousTU = MostRecentTU->getPreviousDecl();
     assert(PreviousTU && "Must have a TU from the ASTContext initialization!");
     TranslationUnitDecl *FirstTU = MostRecentTU->getFirstDecl();
     assert(FirstTU);
     FirstTU->RedeclLink.setLatest(PreviousTU);
     C.TUDecl = PreviousTU;
     S.TUScope->setEntity(PreviousTU);
 
     // Clean up the lookup table
     if (StoredDeclsMap *Map = PreviousTU->getLookupPtr()) {
       for (auto I = Map->begin(); I != Map->end(); ++I) {
         StoredDeclsList &List = I->second;
         DeclContextLookupResult R = List.getLookupResult();
         for (NamedDecl *D : R)
           if (D->getTranslationUnitDecl() == MostRecentTU)
             List.remove(D);
         if (List.isNull())
           Map->erase(I);
       }
     }
 
     // FIXME: Do not reset the pragma handlers.
     Diags.Reset();
     return llvm::make_error<llvm::StringError>("Parsing failed.",
                                                std::error_code());
   }
 
   // Process any TopLevelDecls generated by #pragma weak.
   for (Decl *D : S.WeakTopLevelDecls()) {
     DeclGroupRef DGR(D);
     Consumer->HandleTopLevelDecl(DGR);
   }
 
   LocalInstantiations.perform();
   GlobalInstantiations.perform();
 
   Consumer->HandleTranslationUnit(C);
 
   return LastPTU;
 }
 
 static CodeGenerator *getCodeGen(FrontendAction *Act) {
   IncrementalAction *IncrAct = static_cast<IncrementalAction *>(Act);
   FrontendAction *WrappedAct = IncrAct->getWrapped();
   if (!WrappedAct->hasIRSupport())
     return nullptr;
   return static_cast<CodeGenAction *>(WrappedAct)->getCodeGenerator();
 }
 
 llvm::Expected<PartialTranslationUnit &>
 IncrementalParser::Parse(llvm::StringRef input) {
   Preprocessor &PP = CI->getPreprocessor();
   assert(PP.isIncrementalProcessingEnabled() && "Not in incremental mode!?");
 
   std::ostringstream SourceName;
   SourceName << "input_line_" << InputCount++;
 
   // Create an uninitialized memory buffer, copy code in and append "\n"
   size_t InputSize = input.size(); // don't include trailing 0
   // MemBuffer size should *not* include terminating zero
   std::unique_ptr<llvm::MemoryBuffer> MB(
       llvm::WritableMemoryBuffer::getNewUninitMemBuffer(InputSize + 1,
                                                         SourceName.str()));
   char *MBStart = const_cast<char *>(MB->getBufferStart());
   memcpy(MBStart, input.data(), InputSize);
   MBStart[InputSize] = '\n';
 
   SourceManager &SM = CI->getSourceManager();
 
   // FIXME: Create SourceLocation, which will allow clang to order the overload
   // candidates for example
   SourceLocation NewLoc = SM.getLocForStartOfFile(SM.getMainFileID());
 
   // Create FileID for the current buffer.
   FileID FID = SM.createFileID(std::move(MB), SrcMgr::C_User, /*LoadedID=*/0,
                                /*LoadedOffset=*/0, NewLoc);
 
   // NewLoc only used for diags.
   if (PP.EnterSourceFile(FID, /*DirLookup=*/nullptr, NewLoc))
     return llvm::make_error<llvm::StringError>("Parsing failed. "
                                                "Cannot enter source file.",
                                                std::error_code());
 
   auto PTU = ParseOrWrapTopLevelDecl();
   if (!PTU)
     return PTU.takeError();
 
   if (PP.getLangOpts().DelayedTemplateParsing) {
     // Microsoft-specific:
     // Late parsed templates can leave unswallowed "macro"-like tokens.
     // They will seriously confuse the Parser when entering the next
     // source file. So lex until we are EOF.
     Token Tok;
     do {
       PP.Lex(Tok);
     } while (Tok.isNot(tok::eof));
   }
 
   Token AssertTok;
   PP.Lex(AssertTok);
   assert(AssertTok.is(tok::eof) &&
          "Lexer must be EOF when starting incremental parse!");
 
   if (CodeGenerator *CG = getCodeGen(Act.get())) {
     std::unique_ptr<llvm::Module> M(CG->ReleaseModule());
     CG->StartModule("incr_module_" + std::to_string(PTUs.size()),
                     M->getContext());
 
     PTU->TheModule = std::move(M);
   }
 
   return PTU;
 }
 
 llvm::StringRef IncrementalParser::GetMangledName(GlobalDecl GD) const {
   CodeGenerator *CG = getCodeGen(Act.get());
   assert(CG);
   return CG->GetMangledName(GD);
 }
 
 } // end namespace clang
diff --git a/clang/lib/Interpreter/IncrementalParser.h b/clang/lib/Interpreter/IncrementalParser.h
index d1f454f21239..c6d848a1ca44 100644
--- a/clang/lib/Interpreter/IncrementalParser.h
+++ b/clang/lib/Interpreter/IncrementalParser.h
@@ -1,80 +1,80 @@
 //===--- IncrementalParser.h - Incremental Compilation ----------*- C++ -*-===//
 //
 // Part of the LLVM Project, under the Apache License v2.0 with LLVM Exceptions.
 // See https://llvm.org/LICENSE.txt for license information.
 // SPDX-License-Identifier: Apache-2.0 WITH LLVM-exception
 //
 //===----------------------------------------------------------------------===//
 //
 // This file implements the class which performs incremental code compilation.
 //
 //===----------------------------------------------------------------------===//
 
 #ifndef LLVM_CLANG_LIB_INTERPRETER_INCREMENTALPARSER_H
 #define LLVM_CLANG_LIB_INTERPRETER_INCREMENTALPARSER_H
 
 #include "clang/Interpreter/PartialTranslationUnit.h"
 
 #include "clang/AST/GlobalDecl.h"
 
 #include "llvm/ADT/ArrayRef.h"
 #include "llvm/ADT/StringRef.h"
 #include "llvm/Support/Error.h"
 
 #include <list>
 #include <memory>
 namespace llvm {
 class LLVMContext;
 }
 
 namespace clang {
 class ASTConsumer;
 class CompilerInstance;
 class IncrementalAction;
 class Parser;
 
 /// Provides support for incremental compilation. Keeps track of the state
 /// changes between the subsequent incremental input.
 ///
 class IncrementalParser {
   /// Long-lived, incremental parsing action.
   std::unique_ptr<IncrementalAction> Act;
 
-  /// Compiler instance performing the incremental compilation.
-  std::unique_ptr<CompilerInstance> CI;
+  /// List containing every information about every incrementally parsed piece
+  /// of code.
+  std::list<PartialTranslationUnit> PTUs;
 
   /// Parser.
   std::unique_ptr<Parser> P;
 
+  /// Compiler instance performing the incremental compilation.
+  std::unique_ptr<CompilerInstance> CI;
+
   /// Consumer to process the produced top level decls. Owned by Act.
   ASTConsumer *Consumer = nullptr;
 
   /// Counts the number of direct user input lines that have been parsed.
   unsigned InputCount = 0;
 
-  /// List containing every information about every incrementally parsed piece
-  /// of code.
-  std::list<PartialTranslationUnit> PTUs;
-
 public:
   IncrementalParser(std::unique_ptr<CompilerInstance> Instance,
                     llvm::LLVMContext &LLVMCtx, llvm::Error &Err);
   ~IncrementalParser();
 
   const CompilerInstance *getCI() const { return CI.get(); }
 
   /// Parses incremental input by creating an in-memory file.
   ///\returns a \c PartialTranslationUnit which holds information about the
   /// \c TranslationUnitDecl and \c llvm::Module corresponding to the input.
   llvm::Expected<PartialTranslationUnit &> Parse(llvm::StringRef Input);
 
   /// Uses the CodeGenModule mangled name cache and avoids recomputing.
   ///\returns the mangled name of a \c GD.
   llvm::StringRef GetMangledName(GlobalDecl GD) const;
 
 private:
   llvm::Expected<PartialTranslationUnit &> ParseOrWrapTopLevelDecl();
 };
 } // end namespace clang
 
 #endif // LLVM_CLANG_LIB_INTERPRETER_INCREMENTALPARSER_H
diff --git a/clang/lib/Interpreter/Interpreter.cpp b/clang/lib/Interpreter/Interpreter.cpp
index 5fd6ddfe4eb7..0612e6b53b31 100644
--- a/clang/lib/Interpreter/Interpreter.cpp
+++ b/clang/lib/Interpreter/Interpreter.cpp
@@ -1,266 +1,268 @@
 //===------ Interpreter.cpp - Incremental Compilation and Execution -------===//
 //
 // Part of the LLVM Project, under the Apache License v2.0 with LLVM Exceptions.
 // See https://llvm.org/LICENSE.txt for license information.
 // SPDX-License-Identifier: Apache-2.0 WITH LLVM-exception
 //
 //===----------------------------------------------------------------------===//
 //
 // This file implements the component which performs incremental code
 // compilation and execution.
 //
 //===----------------------------------------------------------------------===//
 
 #include "clang/Interpreter/Interpreter.h"
 
 #include "IncrementalExecutor.h"
 #include "IncrementalParser.h"
 
 #include "clang/AST/ASTContext.h"
 #include "clang/Basic/TargetInfo.h"
 #include "clang/CodeGen/ModuleBuilder.h"
 #include "clang/CodeGen/ObjectFilePCHContainerOperations.h"
 #include "clang/Driver/Compilation.h"
 #include "clang/Driver/Driver.h"
 #include "clang/Driver/Job.h"
 #include "clang/Driver/Options.h"
 #include "clang/Driver/Tool.h"
 #include "clang/Frontend/CompilerInstance.h"
 #include "clang/Frontend/TextDiagnosticBuffer.h"
 #include "clang/Lex/PreprocessorOptions.h"
 
 #include "llvm/IR/Module.h"
 #include "llvm/Support/Errc.h"
 #include "llvm/Support/Host.h"
 
 using namespace clang;
 
 // FIXME: Figure out how to unify with namespace init_convenience from
 //        tools/clang-import-test/clang-import-test.cpp
 namespace {
 /// Retrieves the clang CC1 specific flags out of the compilation's jobs.
 /// \returns NULL on error.
 static llvm::Expected<const llvm::opt::ArgStringList *>
 GetCC1Arguments(DiagnosticsEngine *Diagnostics,
                 driver::Compilation *Compilation) {
   // We expect to get back exactly one Command job, if we didn't something
   // failed. Extract that job from the Compilation.
   const driver::JobList &Jobs = Compilation->getJobs();
   if (!Jobs.size() || !isa<driver::Command>(*Jobs.begin()))
     return llvm::createStringError(llvm::errc::not_supported,
                                    "Driver initialization failed. "
                                    "Unable to create a driver job");
 
   // The one job we find should be to invoke clang again.
   const driver::Command *Cmd = cast<driver::Command>(&(*Jobs.begin()));
   if (llvm::StringRef(Cmd->getCreator().getName()) != "clang")
     return llvm::createStringError(llvm::errc::not_supported,
                                    "Driver initialization failed");
 
   return &Cmd->getArguments();
 }
 
 static llvm::Expected<std::unique_ptr<CompilerInstance>>
 CreateCI(const llvm::opt::ArgStringList &Argv) {
   std::unique_ptr<CompilerInstance> Clang(new CompilerInstance());
   IntrusiveRefCntPtr<DiagnosticIDs> DiagID(new DiagnosticIDs());
 
   // Register the support for object-file-wrapped Clang modules.
   // FIXME: Clang should register these container operations automatically.
   auto PCHOps = Clang->getPCHContainerOperations();
   PCHOps->registerWriter(std::make_unique<ObjectFilePCHContainerWriter>());
   PCHOps->registerReader(std::make_unique<ObjectFilePCHContainerReader>());
 
   // Buffer diagnostics from argument parsing so that we can output them using
   // a well formed diagnostic object.
   IntrusiveRefCntPtr<DiagnosticOptions> DiagOpts = new DiagnosticOptions();
   TextDiagnosticBuffer *DiagsBuffer = new TextDiagnosticBuffer;
   DiagnosticsEngine Diags(DiagID, &*DiagOpts, DiagsBuffer);
   bool Success = CompilerInvocation::CreateFromArgs(
       Clang->getInvocation(), llvm::makeArrayRef(Argv.begin(), Argv.size()),
       Diags);
 
   // Infer the builtin include path if unspecified.
   if (Clang->getHeaderSearchOpts().UseBuiltinIncludes &&
       Clang->getHeaderSearchOpts().ResourceDir.empty())
     Clang->getHeaderSearchOpts().ResourceDir =
         CompilerInvocation::GetResourcesPath(Argv[0], nullptr);
 
   // Create the actual diagnostics engine.
   Clang->createDiagnostics();
   if (!Clang->hasDiagnostics())
     return llvm::createStringError(llvm::errc::not_supported,
                                    "Initialization failed. "
                                    "Unable to create diagnostics engine");
 
   DiagsBuffer->FlushDiagnostics(Clang->getDiagnostics());
   if (!Success)
     return llvm::createStringError(llvm::errc::not_supported,
                                    "Initialization failed. "
                                    "Unable to flush diagnostics");
 
   // FIXME: Merge with CompilerInstance::ExecuteAction.
   llvm::MemoryBuffer *MB = llvm::MemoryBuffer::getMemBuffer("").release();
   Clang->getPreprocessorOpts().addRemappedFile("<<< inputs >>>", MB);
 
   Clang->setTarget(TargetInfo::CreateTargetInfo(
       Clang->getDiagnostics(), Clang->getInvocation().TargetOpts));
   if (!Clang->hasTarget())
     return llvm::createStringError(llvm::errc::not_supported,
                                    "Initialization failed. "
                                    "Target is missing");
 
   Clang->getTarget().adjust(Clang->getDiagnostics(), Clang->getLangOpts());
 
   // Don't clear the AST before backend codegen since we do codegen multiple
   // times, reusing the same AST.
   Clang->getCodeGenOpts().ClearASTBeforeBackend = false;
+  Clang->getFrontendOpts().DisableFree = false;
 
   return std::move(Clang);
 }
 
 } // anonymous namespace
 
 llvm::Expected<std::unique_ptr<CompilerInstance>>
 IncrementalCompilerBuilder::create(std::vector<const char *> &ClangArgv) {
 
   // If we don't know ClangArgv0 or the address of main() at this point, try
   // to guess it anyway (it's possible on some platforms).
   std::string MainExecutableName =
       llvm::sys::fs::getMainExecutable(nullptr, nullptr);
 
   ClangArgv.insert(ClangArgv.begin(), MainExecutableName.c_str());
 
   // Prepending -c to force the driver to do something if no action was
   // specified. By prepending we allow users to override the default
   // action and use other actions in incremental mode.
   // FIXME: Print proper driver diagnostics if the driver flags are wrong.
   ClangArgv.insert(ClangArgv.begin() + 1, "-c");
 
   if (!llvm::is_contained(ClangArgv, " -x")) {
     // We do C++ by default; append right after argv[0] if no "-x" given
     ClangArgv.push_back("-x");
     ClangArgv.push_back("c++");
   }
 
   // Put a dummy C++ file on to ensure there's at least one compile job for the
   // driver to construct.
   ClangArgv.push_back("<<< inputs >>>");
 
   // Buffer diagnostics from argument parsing so that we can output them using a
   // well formed diagnostic object.
   IntrusiveRefCntPtr<DiagnosticIDs> DiagID(new DiagnosticIDs());
   IntrusiveRefCntPtr<DiagnosticOptions> DiagOpts =
       CreateAndPopulateDiagOpts(ClangArgv);
   TextDiagnosticBuffer *DiagsBuffer = new TextDiagnosticBuffer;
   DiagnosticsEngine Diags(DiagID, &*DiagOpts, DiagsBuffer);
 
   driver::Driver Driver(/*MainBinaryName=*/ClangArgv[0],
                         llvm::sys::getProcessTriple(), Diags);
   Driver.setCheckInputsExist(false); // the input comes from mem buffers
   llvm::ArrayRef<const char *> RF = llvm::makeArrayRef(ClangArgv);
   std::unique_ptr<driver::Compilation> Compilation(Driver.BuildCompilation(RF));
 
   if (Compilation->getArgs().hasArg(driver::options::OPT_v))
     Compilation->getJobs().Print(llvm::errs(), "\n", /*Quote=*/false);
 
   auto ErrOrCC1Args = GetCC1Arguments(&Diags, Compilation.get());
   if (auto Err = ErrOrCC1Args.takeError())
     return std::move(Err);
 
   return CreateCI(**ErrOrCC1Args);
 }
 
 Interpreter::Interpreter(std::unique_ptr<CompilerInstance> CI,
                          llvm::Error &Err) {
   llvm::ErrorAsOutParameter EAO(&Err);
   auto LLVMCtx = std::make_unique<llvm::LLVMContext>();
   TSCtx = std::make_unique<llvm::orc::ThreadSafeContext>(std::move(LLVMCtx));
   IncrParser = std::make_unique<IncrementalParser>(std::move(CI),
                                                    *TSCtx->getContext(), Err);
 }
 
 Interpreter::~Interpreter() {
   if (IncrExecutor) {
     if (llvm::Error Err = IncrExecutor->cleanUp())
       llvm::report_fatal_error(
           llvm::Twine("Failed to clean up IncrementalExecutor: ") +
           toString(std::move(Err)));
   }
 }
 
 llvm::Expected<std::unique_ptr<Interpreter>>
 Interpreter::create(std::unique_ptr<CompilerInstance> CI) {
   llvm::Error Err = llvm::Error::success();
   auto Interp =
       std::unique_ptr<Interpreter>(new Interpreter(std::move(CI), Err));
   if (Err)
     return std::move(Err);
   return std::move(Interp);
 }
 
 const CompilerInstance *Interpreter::getCompilerInstance() const {
   return IncrParser->getCI();
 }
 
 const llvm::orc::LLJIT *Interpreter::getExecutionEngine() const {
   if (IncrExecutor)
     return IncrExecutor->getExecutionEngine();
   return nullptr;
 }
 
 llvm::Expected<PartialTranslationUnit &>
 Interpreter::Parse(llvm::StringRef Code) {
   return IncrParser->Parse(Code);
 }
 
 llvm::Error Interpreter::Execute(PartialTranslationUnit &T) {
   assert(T.TheModule);
+  T.TheModule->dump();
   if (!IncrExecutor) {
     const llvm::Triple &Triple =
         getCompilerInstance()->getASTContext().getTargetInfo().getTriple();
     llvm::Error Err = llvm::Error::success();
     IncrExecutor = std::make_unique<IncrementalExecutor>(*TSCtx, Err, Triple);
 
     if (Err)
       return Err;
   }
   // FIXME: Add a callback to retain the llvm::Module once the JIT is done.
   if (auto Err = IncrExecutor->addModule(std::move(T.TheModule)))
     return Err;
 
   if (auto Err = IncrExecutor->runCtors())
     return Err;
 
   return llvm::Error::success();
 }
 
 llvm::Expected<llvm::JITTargetAddress>
 Interpreter::getSymbolAddress(GlobalDecl GD) const {
   if (!IncrExecutor)
     return llvm::make_error<llvm::StringError>("Operation failed. "
                                                "No execution engine",
                                                std::error_code());
   llvm::StringRef MangledName = IncrParser->GetMangledName(GD);
   return getSymbolAddress(MangledName);
 }
 
 llvm::Expected<llvm::JITTargetAddress>
 Interpreter::getSymbolAddress(llvm::StringRef IRName) const {
   if (!IncrExecutor)
     return llvm::make_error<llvm::StringError>("Operation failed. "
                                                "No execution engine",
                                                std::error_code());
 
   return IncrExecutor->getSymbolAddress(IRName, IncrementalExecutor::IRName);
 }
 
 llvm::Expected<llvm::JITTargetAddress>
 Interpreter::getSymbolAddressFromLinkerName(llvm::StringRef Name) const {
   if (!IncrExecutor)
     return llvm::make_error<llvm::StringError>("Operation failed. "
                                                "No execution engine",
                                                std::error_code());
 
   return IncrExecutor->getSymbolAddress(Name, IncrementalExecutor::LinkerName);
 }
diff --git a/clang/tools/clang-repl/ClangRepl.cpp b/clang/tools/clang-repl/ClangRepl.cpp
index 29ab3c23557b..d5c4e7cbe827 100644
--- a/clang/tools/clang-repl/ClangRepl.cpp
+++ b/clang/tools/clang-repl/ClangRepl.cpp
@@ -1,110 +1,118 @@
 //===--- tools/clang-repl/ClangRepl.cpp - clang-repl - the Clang REPL -----===//
 //
 // Part of the LLVM Project, under the Apache License v2.0 with LLVM Exceptions.
 // See https://llvm.org/LICENSE.txt for license information.
 // SPDX-License-Identifier: Apache-2.0 WITH LLVM-exception
 //
 //===----------------------------------------------------------------------===//
 //
 //  This file implements a REPL tool on top of clang.
 //
 //===----------------------------------------------------------------------===//
 
+#define _CRTDBG_MAP_ALLOC
+#include <stdlib.h>
+#include <crtdbg.h>
+
 #include "clang/Basic/Diagnostic.h"
 #include "clang/Frontend/CompilerInstance.h"
 #include "clang/Frontend/FrontendDiagnostic.h"
 #include "clang/Interpreter/Interpreter.h"
 
 #include "llvm/ExecutionEngine/Orc/LLJIT.h"
 #include "llvm/LineEditor/LineEditor.h"
 #include "llvm/Support/CommandLine.h"
 #include "llvm/Support/ManagedStatic.h" // llvm_shutdown
 #include "llvm/Support/Signals.h"
 #include "llvm/Support/TargetSelect.h" // llvm::Initialize*
 
+
 static llvm::cl::list<std::string>
     ClangArgs("Xcc", llvm::cl::ZeroOrMore,
               llvm::cl::desc("Argument to pass to the CompilerInvocation"),
               llvm::cl::CommaSeparated);
 static llvm::cl::opt<bool> OptHostSupportsJit("host-supports-jit",
                                               llvm::cl::Hidden);
 static llvm::cl::list<std::string> OptInputs(llvm::cl::Positional,
                                              llvm::cl::ZeroOrMore,
                                              llvm::cl::desc("[code to run]"));
 
 static void LLVMErrorHandler(void *UserData, const char *Message,
                              bool GenCrashDiag) {
   auto &Diags = *static_cast<clang::DiagnosticsEngine *>(UserData);
 
   Diags.Report(clang::diag::err_fe_error_backend) << Message;
 
   // Run the interrupt handlers to make sure any special cleanups get done, in
   // particular that we remove files registered with RemoveFileOnSignal.
   llvm::sys::RunInterruptHandlers();
 
   // We cannot recover from llvm errors.  When reporting a fatal error, exit
   // with status 70 to generate crash diagnostics.  For BSD systems this is
   // defined as an internal software error. Otherwise, exit with status 1.
 
   exit(GenCrashDiag ? 70 : 1);
 }
 
 llvm::ExitOnError ExitOnErr;
 int main(int argc, const char **argv) {
   ExitOnErr.setBanner("clang-repl: ");
   llvm::cl::ParseCommandLineOptions(argc, argv);
 
   llvm::llvm_shutdown_obj Y; // Call llvm_shutdown() on exit.
   std::vector<const char *> ClangArgv(ClangArgs.size());
   std::transform(ClangArgs.begin(), ClangArgs.end(), ClangArgv.begin(),
                  [](const std::string &s) -> const char * { return s.data(); });
   llvm::InitializeNativeTarget();
   llvm::InitializeNativeTargetAsmPrinter();
 
   if (OptHostSupportsJit) {
     auto J = llvm::orc::LLJITBuilder().create();
     if (J)
       llvm::outs() << "true\n";
     else {
       llvm::consumeError(J.takeError());
       llvm::outs() << "false\n";
     }
     return 0;
   }
+  auto x = new int();
+  llvm::outs() << x << "\n";
 
   // FIXME: Investigate if we could use runToolOnCodeWithArgs from tooling. It
   // can replace the boilerplate code for creation of the compiler instance.
   auto CI = ExitOnErr(clang::IncrementalCompilerBuilder::create(ClangArgv));
 
   // Set an error handler, so that any LLVM backend diagnostics go through our
   // error handler.
   llvm::install_fatal_error_handler(LLVMErrorHandler,
                                     static_cast<void *>(&CI->getDiagnostics()));
 
   // Load any requested plugins.
   CI->LoadRequestedPlugins();
 
   auto Interp = ExitOnErr(clang::Interpreter::create(std::move(CI)));
   for (const std::string &input : OptInputs) {
     if (auto Err = Interp->ParseAndExecute(input))
       llvm::logAllUnhandledErrors(std::move(Err), llvm::errs(), "error: ");
   }
 
   if (OptInputs.empty()) {
     llvm::LineEditor LE("clang-repl");
     // FIXME: Add LE.setListCompleter
     while (llvm::Optional<std::string> Line = LE.readLine()) {
       if (*Line == "quit")
         break;
       if (auto Err = Interp->ParseAndExecute(*Line))
         llvm::logAllUnhandledErrors(std::move(Err), llvm::errs(), "error: ");
     }
   }
 
   // Our error handler depends on the Diagnostics object, which we're
   // potentially about to delete. Uninstall the handler now so that any
   // later errors use the default handling behavior instead.
   llvm::remove_fatal_error_handler();
 
+  _CrtDumpMemoryLeaks();
   return 0;
 }
diff --git a/llvm/include/llvm/ADT/IntrusiveRefCntPtr.h b/llvm/include/llvm/ADT/IntrusiveRefCntPtr.h
index e41eb0639ce3..74025398926a 100644
--- a/llvm/include/llvm/ADT/IntrusiveRefCntPtr.h
+++ b/llvm/include/llvm/ADT/IntrusiveRefCntPtr.h
@@ -1,310 +1,310 @@
 //==- llvm/ADT/IntrusiveRefCntPtr.h - Smart Refcounting Pointer --*- C++ -*-==//
 //
 // Part of the LLVM Project, under the Apache License v2.0 with LLVM Exceptions.
 // See https://llvm.org/LICENSE.txt for license information.
 // SPDX-License-Identifier: Apache-2.0 WITH LLVM-exception
 //
 //===----------------------------------------------------------------------===//
 ///
 /// \file
 /// This file defines the RefCountedBase, ThreadSafeRefCountedBase, and
 /// IntrusiveRefCntPtr classes.
 ///
 /// IntrusiveRefCntPtr is a smart pointer to an object which maintains a
 /// reference count.  (ThreadSafe)RefCountedBase is a mixin class that adds a
 /// refcount member variable and methods for updating the refcount.  An object
 /// that inherits from (ThreadSafe)RefCountedBase deletes itself when its
 /// refcount hits zero.
 ///
 /// For example:
 ///
 /// ```
 ///   class MyClass : public RefCountedBase<MyClass> {};
 ///
 ///   void foo() {
 ///     // Constructing an IntrusiveRefCntPtr increases the pointee's refcount
 ///     // by 1 (from 0 in this case).
 ///     IntrusiveRefCntPtr<MyClass> Ptr1(new MyClass());
 ///
 ///     // Copying an IntrusiveRefCntPtr increases the pointee's refcount by 1.
 ///     IntrusiveRefCntPtr<MyClass> Ptr2(Ptr1);
 ///
 ///     // Constructing an IntrusiveRefCntPtr has no effect on the object's
 ///     // refcount.  After a move, the moved-from pointer is null.
 ///     IntrusiveRefCntPtr<MyClass> Ptr3(std::move(Ptr1));
 ///     assert(Ptr1 == nullptr);
 ///
 ///     // Clearing an IntrusiveRefCntPtr decreases the pointee's refcount by 1.
 ///     Ptr2.reset();
 ///
 ///     // The object deletes itself when we return from the function, because
 ///     // Ptr3's destructor decrements its refcount to 0.
 ///   }
 /// ```
 ///
 /// You can use IntrusiveRefCntPtr with isa<T>(), dyn_cast<T>(), etc.:
 ///
 /// ```
 ///   IntrusiveRefCntPtr<MyClass> Ptr(new MyClass());
 ///   OtherClass *Other = dyn_cast<OtherClass>(Ptr);  // Ptr.get() not required
 /// ```
 ///
 /// IntrusiveRefCntPtr works with any class that
 ///
 ///  - inherits from (ThreadSafe)RefCountedBase,
 ///  - has Retain() and Release() methods, or
 ///  - specializes IntrusiveRefCntPtrInfo.
 ///
 //===----------------------------------------------------------------------===//
 
 #ifndef LLVM_ADT_INTRUSIVEREFCNTPTR_H
 #define LLVM_ADT_INTRUSIVEREFCNTPTR_H
 
 #include <atomic>
 #include <cassert>
 #include <cstddef>
 #include <memory>
 
 namespace llvm {
 
 /// A CRTP mixin class that adds reference counting to a type.
 ///
 /// The lifetime of an object which inherits from RefCountedBase is managed by
 /// calls to Release() and Retain(), which increment and decrement the object's
 /// refcount, respectively.  When a Release() call decrements the refcount to 0,
 /// the object deletes itself.
 template <class Derived> class RefCountedBase {
   mutable unsigned RefCount = 0;
 
 protected:
   RefCountedBase() = default;
   RefCountedBase(const RefCountedBase &) {}
   RefCountedBase &operator=(const RefCountedBase &) = delete;
 
-#ifndef NDEBUG
+//#ifndef NDEBUG
   ~RefCountedBase() {
     assert(RefCount == 0 &&
            "Destruction occurred when there are still references to this.");
   }
-#else
+/*#else
   // Default the destructor in release builds, A trivial destructor may enable
   // better codegen.
   ~RefCountedBase() = default;
-#endif
+#endif*/
 
 public:
   void Retain() const { ++RefCount; }
 
   void Release() const {
     assert(RefCount > 0 && "Reference count is already zero.");
     if (--RefCount == 0)
       delete static_cast<const Derived *>(this);
   }
 };
 
 /// A thread-safe version of \c RefCountedBase.
 template <class Derived> class ThreadSafeRefCountedBase {
   mutable std::atomic<int> RefCount{0};
 
 protected:
   ThreadSafeRefCountedBase() = default;
   ThreadSafeRefCountedBase(const ThreadSafeRefCountedBase &) {}
   ThreadSafeRefCountedBase &
   operator=(const ThreadSafeRefCountedBase &) = delete;
 
 #ifndef NDEBUG
   ~ThreadSafeRefCountedBase() {
     assert(RefCount == 0 &&
            "Destruction occurred when there are still references to this.");
   }
 #else
   // Default the destructor in release builds, A trivial destructor may enable
   // better codegen.
   ~ThreadSafeRefCountedBase() = default;
 #endif
 
 public:
   void Retain() const { RefCount.fetch_add(1, std::memory_order_relaxed); }
 
   void Release() const {
     int NewRefCount = RefCount.fetch_sub(1, std::memory_order_acq_rel) - 1;
     assert(NewRefCount >= 0 && "Reference count was already zero.");
     if (NewRefCount == 0)
       delete static_cast<const Derived *>(this);
   }
 };
 
 /// Class you can specialize to provide custom retain/release functionality for
 /// a type.
 ///
 /// Usually specializing this class is not necessary, as IntrusiveRefCntPtr
 /// works with any type which defines Retain() and Release() functions -- you
 /// can define those functions yourself if RefCountedBase doesn't work for you.
 ///
 /// One case when you might want to specialize this type is if you have
 ///  - Foo.h defines type Foo and includes Bar.h, and
 ///  - Bar.h uses IntrusiveRefCntPtr<Foo> in inline functions.
 ///
 /// Because Foo.h includes Bar.h, Bar.h can't include Foo.h in order to pull in
 /// the declaration of Foo.  Without the declaration of Foo, normally Bar.h
 /// wouldn't be able to use IntrusiveRefCntPtr<Foo>, which wants to call
 /// T::Retain and T::Release.
 ///
 /// To resolve this, Bar.h could include a third header, FooFwd.h, which
 /// forward-declares Foo and specializes IntrusiveRefCntPtrInfo<Foo>.  Then
 /// Bar.h could use IntrusiveRefCntPtr<Foo>, although it still couldn't call any
 /// functions on Foo itself, because Foo would be an incomplete type.
 template <typename T> struct IntrusiveRefCntPtrInfo {
   static void retain(T *obj) { obj->Retain(); }
   static void release(T *obj) { obj->Release(); }
 };
 
 /// A smart pointer to a reference-counted object that inherits from
 /// RefCountedBase or ThreadSafeRefCountedBase.
 ///
 /// This class increments its pointee's reference count when it is created, and
 /// decrements its refcount when it's destroyed (or is changed to point to a
 /// different object).
 template <typename T> class IntrusiveRefCntPtr {
   T *Obj = nullptr;
 
 public:
   using element_type = T;
 
   explicit IntrusiveRefCntPtr() = default;
   IntrusiveRefCntPtr(T *obj) : Obj(obj) { retain(); }
   IntrusiveRefCntPtr(const IntrusiveRefCntPtr &S) : Obj(S.Obj) { retain(); }
   IntrusiveRefCntPtr(IntrusiveRefCntPtr &&S) : Obj(S.Obj) { S.Obj = nullptr; }
 
   template <class X,
             std::enable_if_t<std::is_convertible<X *, T *>::value, bool> = true>
   IntrusiveRefCntPtr(IntrusiveRefCntPtr<X> S) : Obj(S.get()) {
     S.Obj = nullptr;
   }
 
   template <class X,
             std::enable_if_t<std::is_convertible<X *, T *>::value, bool> = true>
   IntrusiveRefCntPtr(std::unique_ptr<X> S) : Obj(S.release()) {
     retain();
   }
 
   ~IntrusiveRefCntPtr() { release(); }
 
   IntrusiveRefCntPtr &operator=(IntrusiveRefCntPtr S) {
     swap(S);
     return *this;
   }
 
   T &operator*() const { return *Obj; }
   T *operator->() const { return Obj; }
   T *get() const { return Obj; }
   explicit operator bool() const { return Obj; }
 
   void swap(IntrusiveRefCntPtr &other) {
     T *tmp = other.Obj;
     other.Obj = Obj;
     Obj = tmp;
   }
 
   void reset() {
     release();
     Obj = nullptr;
   }
 
   void resetWithoutRelease() { Obj = nullptr; }
 
 private:
   void retain() {
     if (Obj)
       IntrusiveRefCntPtrInfo<T>::retain(Obj);
   }
 
   void release() {
     if (Obj)
       IntrusiveRefCntPtrInfo<T>::release(Obj);
   }
 
   template <typename X> friend class IntrusiveRefCntPtr;
 };
 
 template <class T, class U>
 inline bool operator==(const IntrusiveRefCntPtr<T> &A,
                        const IntrusiveRefCntPtr<U> &B) {
   return A.get() == B.get();
 }
 
 template <class T, class U>
 inline bool operator!=(const IntrusiveRefCntPtr<T> &A,
                        const IntrusiveRefCntPtr<U> &B) {
   return A.get() != B.get();
 }
 
 template <class T, class U>
 inline bool operator==(const IntrusiveRefCntPtr<T> &A, U *B) {
   return A.get() == B;
 }
 
 template <class T, class U>
 inline bool operator!=(const IntrusiveRefCntPtr<T> &A, U *B) {
   return A.get() != B;
 }
 
 template <class T, class U>
 inline bool operator==(T *A, const IntrusiveRefCntPtr<U> &B) {
   return A == B.get();
 }
 
 template <class T, class U>
 inline bool operator!=(T *A, const IntrusiveRefCntPtr<U> &B) {
   return A != B.get();
 }
 
 template <class T>
 bool operator==(std::nullptr_t, const IntrusiveRefCntPtr<T> &B) {
   return !B;
 }
 
 template <class T>
 bool operator==(const IntrusiveRefCntPtr<T> &A, std::nullptr_t B) {
   return B == A;
 }
 
 template <class T>
 bool operator!=(std::nullptr_t A, const IntrusiveRefCntPtr<T> &B) {
   return !(A == B);
 }
 
 template <class T>
 bool operator!=(const IntrusiveRefCntPtr<T> &A, std::nullptr_t B) {
   return !(A == B);
 }
 
 // Make IntrusiveRefCntPtr work with dyn_cast, isa, and the other idioms from
 // Casting.h.
 template <typename From> struct simplify_type;
 
 template <class T> struct simplify_type<IntrusiveRefCntPtr<T>> {
   using SimpleType = T *;
 
   static SimpleType getSimplifiedValue(IntrusiveRefCntPtr<T> &Val) {
     return Val.get();
   }
 };
 
 template <class T> struct simplify_type<const IntrusiveRefCntPtr<T>> {
   using SimpleType = /*const*/ T *;
 
   static SimpleType getSimplifiedValue(const IntrusiveRefCntPtr<T> &Val) {
     return Val.get();
   }
 };
 
 /// Factory function for creating intrusive ref counted pointers.
 template <typename T, typename... Args>
 IntrusiveRefCntPtr<T> makeIntrusiveRefCnt(Args &&...A) {
   return IntrusiveRefCntPtr<T>(new T(std::forward<Args>(A)...));
 }
 
 } // end namespace llvm
 
 #endif // LLVM_ADT_INTRUSIVEREFCNTPTR_H
diff --git a/llvm/include/llvm/Support/ManagedStatic.h b/llvm/include/llvm/Support/ManagedStatic.h
index f2b41422f131..2889c00cdf0d 100644
--- a/llvm/include/llvm/Support/ManagedStatic.h
+++ b/llvm/include/llvm/Support/ManagedStatic.h
@@ -1,125 +1,127 @@
 //===-- llvm/Support/ManagedStatic.h - Static Global wrapper ----*- C++ -*-===//
 //
 // Part of the LLVM Project, under the Apache License v2.0 with LLVM Exceptions.
 // See https://llvm.org/LICENSE.txt for license information.
 // SPDX-License-Identifier: Apache-2.0 WITH LLVM-exception
 //
 //===----------------------------------------------------------------------===//
 //
 // This file defines the ManagedStatic class and the llvm_shutdown() function.
 //
 //===----------------------------------------------------------------------===//
 
 #ifndef LLVM_SUPPORT_MANAGEDSTATIC_H
 #define LLVM_SUPPORT_MANAGEDSTATIC_H
 
 #include <atomic>
 #include <cstddef>
 
 namespace llvm {
 
 /// object_creator - Helper method for ManagedStatic.
 template <class C> struct object_creator {
   static void *call() { return new C(); }
 };
 
 /// object_deleter - Helper method for ManagedStatic.
 ///
 template <typename T> struct object_deleter {
   static void call(void *Ptr) { delete (T *)Ptr; }
 };
 template <typename T, size_t N> struct object_deleter<T[N]> {
   static void call(void *Ptr) { delete[](T *)Ptr; }
 };
 
 // ManagedStatic must be initialized to zero, and it must *not* have a dynamic
 // initializer because managed statics are often created while running other
 // dynamic initializers. In standard C++11, the best way to accomplish this is
 // with a constexpr default constructor. However, different versions of the
 // Visual C++ compiler have had bugs where, even though the constructor may be
 // constexpr, a dynamic initializer may be emitted depending on optimization
 // settings. For the affected versions of MSVC, use the old linker
 // initialization pattern of not providing a constructor and leaving the fields
 // uninitialized. See http://llvm.org/PR41367 for details.
 #if !defined(_MSC_VER) || (_MSC_VER >= 1925) || defined(__clang__)
 #define LLVM_USE_CONSTEXPR_CTOR
 #endif
 
 /// ManagedStaticBase - Common base class for ManagedStatic instances.
 class ManagedStaticBase {
 protected:
 #ifdef LLVM_USE_CONSTEXPR_CTOR
   mutable std::atomic<void *> Ptr{};
   mutable void (*DeleterFn)(void *) = nullptr;
   mutable const ManagedStaticBase *Next = nullptr;
 #else
   // This should only be used as a static variable, which guarantees that this
   // will be zero initialized.
   mutable std::atomic<void *> Ptr;
   mutable void (*DeleterFn)(void *);
   mutable const ManagedStaticBase *Next;
 #endif
 
   void RegisterManagedStatic(void *(*creator)(), void (*deleter)(void*)) const;
 
 public:
 #ifdef LLVM_USE_CONSTEXPR_CTOR
   constexpr ManagedStaticBase() = default;
 #endif
 
   /// isConstructed - Return true if this object has not been created yet.
   bool isConstructed() const { return Ptr != nullptr; }
 
   void destroy() const;
 };
 
 /// ManagedStatic - This transparently changes the behavior of global statics to
 /// be lazily constructed on demand (good for reducing startup times of dynamic
 /// libraries that link in LLVM components) and for making destruction be
 /// explicit through the llvm_shutdown() function call.
 ///
 template <class C, class Creator = object_creator<C>,
           class Deleter = object_deleter<C>>
 class ManagedStatic : public ManagedStaticBase {
 public:
   // Accessors.
   C &operator*() {
     void *Tmp = Ptr.load(std::memory_order_acquire);
     if (!Tmp)
       RegisterManagedStatic(Creator::call, Deleter::call);
 
     return *static_cast<C *>(Ptr.load(std::memory_order_relaxed));
   }
 
   C *operator->() { return &**this; }
 
   const C &operator*() const {
     void *Tmp = Ptr.load(std::memory_order_acquire);
     if (!Tmp)
       RegisterManagedStatic(Creator::call, Deleter::call);
 
     return *static_cast<C *>(Ptr.load(std::memory_order_relaxed));
   }
 
   const C *operator->() const { return &**this; }
 
   // Extract the instance, leaving the ManagedStatic uninitialized. The
   // user is then responsible for the lifetime of the returned instance.
   C *claim() {
     return static_cast<C *>(Ptr.exchange(nullptr));
   }
 };
 
 /// llvm_shutdown - Deallocate and destroy all ManagedStatic variables.
 void llvm_shutdown();
 
 /// llvm_shutdown_obj - This is a simple helper class that calls
 /// llvm_shutdown() when it is destroyed.
 struct llvm_shutdown_obj {
   llvm_shutdown_obj() = default;
-  ~llvm_shutdown_obj() { llvm_shutdown(); }
+  ~llvm_shutdown_obj() { 
+      llvm_shutdown(); 
+  }
 };
 
 } // end namespace llvm
 
 #endif // LLVM_SUPPORT_MANAGEDSTATIC_H
diff --git a/llvm/lib/ExecutionEngine/JITLink/ELF_aarch64.cpp b/llvm/lib/ExecutionEngine/JITLink/ELF_aarch64.cpp
index 36527a2435c5..0d8ed7e9eb44 100644
--- a/llvm/lib/ExecutionEngine/JITLink/ELF_aarch64.cpp
+++ b/llvm/lib/ExecutionEngine/JITLink/ELF_aarch64.cpp
@@ -1,273 +1,273 @@
 //===----- ELF_aarch64.cpp - JIT linker implementation for ELF/aarch64 ----===//
 //
 // Part of the LLVM Project, under the Apache License v2.0 with LLVM Exceptions.
 // See https://llvm.org/LICENSE.txt for license information.
 // SPDX-License-Identifier: Apache-2.0 WITH LLVM-exception
 //
 //===----------------------------------------------------------------------===//
 //
 // ELF/aarch64 jit-link implementation.
 //
 //===----------------------------------------------------------------------===//
 
 #include "llvm/ExecutionEngine/JITLink/ELF_aarch64.h"
 #include "ELFLinkGraphBuilder.h"
 #include "JITLinkGeneric.h"
 #include "llvm/BinaryFormat/ELF.h"
 #include "llvm/ExecutionEngine/JITLink/aarch64.h"
 #include "llvm/Object/ELFObjectFile.h"
 #include "llvm/Support/MathExtras.h"
 
 #define DEBUG_TYPE "jitlink"
 
 using namespace llvm;
 using namespace llvm::jitlink;
 using namespace llvm::jitlink::ELF_aarch64_Edges;
 
 namespace llvm {
 namespace jitlink {
 
 class ELFJITLinker_aarch64 : public JITLinker<ELFJITLinker_aarch64> {
   friend class JITLinker<ELFJITLinker_aarch64>;
 
 public:
   ELFJITLinker_aarch64(std::unique_ptr<JITLinkContext> Ctx,
                        std::unique_ptr<LinkGraph> G,
                        PassConfiguration PassConfig)
       : JITLinker(std::move(Ctx), std::move(G), std::move(PassConfig)) {}
 
 private:
   Error applyFixup(LinkGraph &G, Block &B, const Edge &E) const {
     return aarch64::applyFixup(G, B, E);
   }
 };
 
 template <typename ELFT>
 class ELFLinkGraphBuilder_aarch64 : public ELFLinkGraphBuilder<ELFT> {
 private:
   static Expected<ELF_aarch64_Edges::ELFAArch64RelocationKind>
   getRelocationKind(const uint32_t Type) {
     using namespace aarch64;
     switch (Type) {
     case ELF::R_AARCH64_CALL26:
       return ELFCall26;
     case ELF::R_AARCH64_ADR_PREL_PG_HI21:
       return ELFAdrPage21;
     case ELF::R_AARCH64_ADD_ABS_LO12_NC:
       return ELFAddAbs12;
     case ELF::R_AARCH64_LDST8_ABS_LO12_NC:
       return ELFLdSt8Abs12;
     case ELF::R_AARCH64_LDST16_ABS_LO12_NC:
       return ELFLdSt16Abs12;
     case ELF::R_AARCH64_LDST32_ABS_LO12_NC:
       return ELFLdSt32Abs12;
     case ELF::R_AARCH64_LDST64_ABS_LO12_NC:
       return ELFLdSt64Abs12;
     case ELF::R_AARCH64_LDST128_ABS_LO12_NC:
       return ELFLdSt128Abs12;
     }
 
     return make_error<JITLinkError>("Unsupported aarch64 relocation:" +
                                     formatv("{0:d}", Type));
   }
 
   Error addRelocations() override {
     LLVM_DEBUG(dbgs() << "Processing relocations:\n");
 
     using Base = ELFLinkGraphBuilder<ELFT>;
     using Self = ELFLinkGraphBuilder_aarch64<ELFT>;
     for (const auto &RelSect : Base::Sections)
       if (Error Err = Base::forEachRelocation(RelSect, this,
                                               &Self::addSingleRelocation))
         return Err;
 
     return Error::success();
   }
 
   Error addSingleRelocation(const typename ELFT::Rela &Rel,
                             const typename ELFT::Shdr &FixupSect,
                             Block &BlockToFix) {
-    using namespace support;
+    using support::ulittle32_t;
     using Base = ELFLinkGraphBuilder<ELFT>;
 
     uint32_t SymbolIndex = Rel.getSymbol(false);
     auto ObjSymbol = Base::Obj.getRelocationSymbol(Rel, Base::SymTabSec);
     if (!ObjSymbol)
       return ObjSymbol.takeError();
 
     Symbol *GraphSymbol = Base::getGraphSymbol(SymbolIndex);
     if (!GraphSymbol)
       return make_error<StringError>(
           formatv("Could not find symbol at given index, did you add it to "
                   "JITSymbolTable? index: {0}, shndx: {1} Size of table: {2}",
                   SymbolIndex, (*ObjSymbol)->st_shndx,
                   Base::GraphSymbols.size()),
           inconvertibleErrorCode());
 
     uint32_t Type = Rel.getType(false);
     Expected<ELF_aarch64_Edges::ELFAArch64RelocationKind> RelocKind =
         getRelocationKind(Type);
     if (!RelocKind)
       return RelocKind.takeError();
 
     int64_t Addend = Rel.r_addend;
     orc::ExecutorAddr FixupAddress =
         orc::ExecutorAddr(FixupSect.sh_addr) + Rel.r_offset;
     Edge::OffsetT Offset = FixupAddress - BlockToFix.getAddress();
 
     // Get a pointer to the fixup content.
     const void *FixupContent = BlockToFix.getContent().data() +
                                (FixupAddress - BlockToFix.getAddress());
 
     Edge::Kind Kind = Edge::Invalid;
 
     switch (*RelocKind) {
     case ELFCall26: {
       Kind = aarch64::Branch26;
       break;
     }
     case ELFAdrPage21: {
       Kind = aarch64::Page21;
       break;
     }
     case ELFAddAbs12: {
       Kind = aarch64::PageOffset12;
       break;
     }
     case ELFLdSt8Abs12: {
       uint32_t Instr = *(const ulittle32_t *)FixupContent;
       if (!aarch64::isLoadStoreImm12(Instr) ||
           aarch64::getPageOffset12Shift(Instr) != 0)
         return make_error<JITLinkError>(
             "R_AARCH64_LDST8_ABS_LO12_NC target is not a "
             "LDRB/STRB (imm12) instruction");
 
       Kind = aarch64::PageOffset12;
       break;
     }
     case ELFLdSt16Abs12: {
       uint32_t Instr = *(const ulittle32_t *)FixupContent;
       if (!aarch64::isLoadStoreImm12(Instr) ||
           aarch64::getPageOffset12Shift(Instr) != 1)
         return make_error<JITLinkError>(
             "R_AARCH64_LDST16_ABS_LO12_NC target is not a "
             "LDRH/STRH (imm12) instruction");
 
       Kind = aarch64::PageOffset12;
       break;
     }
     case ELFLdSt32Abs12: {
       uint32_t Instr = *(const ulittle32_t *)FixupContent;
       if (!aarch64::isLoadStoreImm12(Instr) ||
           aarch64::getPageOffset12Shift(Instr) != 2)
         return make_error<JITLinkError>(
             "R_AARCH64_LDST32_ABS_LO12_NC target is not a "
             "LDR/STR (imm12, 32 bit) instruction");
 
       Kind = aarch64::PageOffset12;
       break;
     }
     case ELFLdSt64Abs12: {
       uint32_t Instr = *(const ulittle32_t *)FixupContent;
       if (!aarch64::isLoadStoreImm12(Instr) ||
           aarch64::getPageOffset12Shift(Instr) != 3)
         return make_error<JITLinkError>(
             "R_AARCH64_LDST64_ABS_LO12_NC target is not a "
             "LDR/STR (imm12, 64 bit) instruction");
 
       Kind = aarch64::PageOffset12;
       break;
     }
     case ELFLdSt128Abs12: {
       uint32_t Instr = *(const ulittle32_t *)FixupContent;
       if (!aarch64::isLoadStoreImm12(Instr) ||
           aarch64::getPageOffset12Shift(Instr) != 4)
         return make_error<JITLinkError>(
             "R_AARCH64_LDST128_ABS_LO12_NC target is not a "
             "LDR/STR (imm12, 128 bit) instruction");
 
       Kind = aarch64::PageOffset12;
       break;
     }
     };
 
     Edge GE(Kind, Offset, *GraphSymbol, Addend);
     LLVM_DEBUG({
       dbgs() << "    ";
       printEdge(dbgs(), BlockToFix, GE, aarch64::getEdgeKindName(Kind));
       dbgs() << "\n";
     });
 
     BlockToFix.addEdge(std::move(GE));
     return Error::success();
   }
 
 public:
   ELFLinkGraphBuilder_aarch64(StringRef FileName,
                               const object::ELFFile<ELFT> &Obj, const Triple T)
       : ELFLinkGraphBuilder<ELFT>(Obj, std::move(T), FileName,
                                   aarch64::getEdgeKindName) {}
 };
 
 Expected<std::unique_ptr<LinkGraph>>
 createLinkGraphFromELFObject_aarch64(MemoryBufferRef ObjectBuffer) {
   LLVM_DEBUG({
     dbgs() << "Building jitlink graph for new input "
            << ObjectBuffer.getBufferIdentifier() << "...\n";
   });
 
   auto ELFObj = object::ObjectFile::createELFObjectFile(ObjectBuffer);
   if (!ELFObj)
     return ELFObj.takeError();
 
   assert((*ELFObj)->getArch() == Triple::aarch64 &&
          "Only AArch64 (little endian) is supported for now");
 
   auto &ELFObjFile = cast<object::ELFObjectFile<object::ELF64LE>>(**ELFObj);
   return ELFLinkGraphBuilder_aarch64<object::ELF64LE>((*ELFObj)->getFileName(),
                                                       ELFObjFile.getELFFile(),
                                                       (*ELFObj)->makeTriple())
       .buildGraph();
 }
 
 void link_ELF_aarch64(std::unique_ptr<LinkGraph> G,
                       std::unique_ptr<JITLinkContext> Ctx) {
   PassConfiguration Config;
   const Triple &TT = G->getTargetTriple();
   if (Ctx->shouldAddDefaultTargetPasses(TT)) {
     if (auto MarkLive = Ctx->getMarkLivePass(TT))
       Config.PrePrunePasses.push_back(std::move(MarkLive));
     else
       Config.PrePrunePasses.push_back(markAllSymbolsLive);
   }
   if (auto Err = Ctx->modifyPassConfig(*G, Config))
     return Ctx->notifyFailed(std::move(Err));
 
   ELFJITLinker_aarch64::link(std::move(Ctx), std::move(G), std::move(Config));
 }
 
 const char *getELFAArch64RelocationKindName(Edge::Kind R) {
   switch (R) {
   case ELFCall26:
     return "ELFCall26";
   case ELFAdrPage21:
     return "ELFAdrPage21";
   case ELFAddAbs12:
     return "ELFAddAbs12";
   case ELFLdSt8Abs12:
     return "ELFLdSt8Abs12";
   case ELFLdSt16Abs12:
     return "ELFLdSt16Abs12";
   case ELFLdSt32Abs12:
     return "ELFLdSt32Abs12";
   case ELFLdSt64Abs12:
     return "ELFLdSt64Abs12";
   case ELFLdSt128Abs12:
     return "ELFLdSt128Abs12";
   default:
     return getGenericEdgeKindName(static_cast<Edge::Kind>(R));
   }
 }
 
 } // namespace jitlink
 } // namespace llvm
diff --git a/llvm/lib/ExecutionEngine/Orc/LLJIT.cpp b/llvm/lib/ExecutionEngine/Orc/LLJIT.cpp
index 8a8b285217bf..0ccbfef09b72 100644
--- a/llvm/lib/ExecutionEngine/Orc/LLJIT.cpp
+++ b/llvm/lib/ExecutionEngine/Orc/LLJIT.cpp
@@ -1,933 +1,942 @@
 //===--------- LLJIT.cpp - An ORC-based JIT for compiling LLVM IR ---------===//
 //
 // Part of the LLVM Project, under the Apache License v2.0 with LLVM Exceptions.
 // See https://llvm.org/LICENSE.txt for license information.
 // SPDX-License-Identifier: Apache-2.0 WITH LLVM-exception
 //
 //===----------------------------------------------------------------------===//
 
 #include "llvm/ExecutionEngine/Orc/LLJIT.h"
 #include "llvm/ExecutionEngine/JITLink/EHFrameSupport.h"
 #include "llvm/ExecutionEngine/JITLink/JITLinkMemoryManager.h"
 #include "llvm/ExecutionEngine/Orc/ExecutorProcessControl.h"
 #include "llvm/ExecutionEngine/Orc/MachOPlatform.h"
 #include "llvm/ExecutionEngine/Orc/ObjectLinkingLayer.h"
 #include "llvm/ExecutionEngine/Orc/ObjectTransformLayer.h"
 #include "llvm/ExecutionEngine/Orc/RTDyldObjectLinkingLayer.h"
 #include "llvm/ExecutionEngine/Orc/Shared/OrcError.h"
 #include "llvm/ExecutionEngine/SectionMemoryManager.h"
 #include "llvm/IR/GlobalVariable.h"
 #include "llvm/IR/IRBuilder.h"
 #include "llvm/IR/Mangler.h"
 #include "llvm/IR/Module.h"
 #include "llvm/Support/DynamicLibrary.h"
 
 #include <map>
 
 #define DEBUG_TYPE "orc"
 
 using namespace llvm;
 using namespace llvm::orc;
 
 namespace {
 
 /// Adds helper function decls and wrapper functions that call the helper with
 /// some additional prefix arguments.
 ///
 /// E.g. For wrapper "foo" with type i8(i8, i64), helper "bar", and prefix
 /// args i32 4 and i16 12345, this function will add:
 ///
 /// declare i8 @bar(i32, i16, i8, i64)
 ///
 /// define i8 @foo(i8, i64) {
 /// entry:
 ///   %2 = call i8 @bar(i32 4, i16 12345, i8 %0, i64 %1)
 ///   ret i8 %2
 /// }
 ///
 Function *addHelperAndWrapper(Module &M, StringRef WrapperName,
                               FunctionType *WrapperFnType,
                               GlobalValue::VisibilityTypes WrapperVisibility,
                               StringRef HelperName,
                               ArrayRef<Value *> HelperPrefixArgs) {
   std::vector<Type *> HelperArgTypes;
   for (auto *Arg : HelperPrefixArgs)
     HelperArgTypes.push_back(Arg->getType());
   for (auto *T : WrapperFnType->params())
     HelperArgTypes.push_back(T);
   auto *HelperFnType =
       FunctionType::get(WrapperFnType->getReturnType(), HelperArgTypes, false);
   auto *HelperFn = Function::Create(HelperFnType, GlobalValue::ExternalLinkage,
                                     HelperName, M);
 
   auto *WrapperFn = Function::Create(
       WrapperFnType, GlobalValue::ExternalLinkage, WrapperName, M);
   WrapperFn->setVisibility(WrapperVisibility);
 
   auto *EntryBlock = BasicBlock::Create(M.getContext(), "entry", WrapperFn);
   IRBuilder<> IB(EntryBlock);
 
   std::vector<Value *> HelperArgs;
   for (auto *Arg : HelperPrefixArgs)
     HelperArgs.push_back(Arg);
   for (auto &Arg : WrapperFn->args())
     HelperArgs.push_back(&Arg);
   auto *HelperResult = IB.CreateCall(HelperFn, HelperArgs);
   if (HelperFn->getReturnType()->isVoidTy())
     IB.CreateRetVoid();
   else
     IB.CreateRet(HelperResult);
 
   return WrapperFn;
 }
 
 class GenericLLVMIRPlatformSupport;
 
 /// orc::Platform component of Generic LLVM IR Platform support.
 /// Just forwards calls to the GenericLLVMIRPlatformSupport class below.
 class GenericLLVMIRPlatform : public Platform {
 public:
   GenericLLVMIRPlatform(GenericLLVMIRPlatformSupport &S) : S(S) {}
   Error setupJITDylib(JITDylib &JD) override;
   Error teardownJITDylib(JITDylib &JD) override;
   Error notifyAdding(ResourceTracker &RT,
                      const MaterializationUnit &MU) override;
   Error notifyRemoving(ResourceTracker &RT) override {
     // Noop -- Nothing to do (yet).
     return Error::success();
   }
 
 private:
   GenericLLVMIRPlatformSupport &S;
 };
 
 /// This transform parses llvm.global_ctors to produce a single initialization
 /// function for the module, records the function, then deletes
 /// llvm.global_ctors.
 class GlobalCtorDtorScraper {
 public:
   GlobalCtorDtorScraper(GenericLLVMIRPlatformSupport &PS,
                         StringRef InitFunctionPrefix,
                         StringRef DeInitFunctionPrefix)
       : PS(PS), InitFunctionPrefix(InitFunctionPrefix),
         DeInitFunctionPrefix(DeInitFunctionPrefix) {}
   Expected<ThreadSafeModule> operator()(ThreadSafeModule TSM,
                                         MaterializationResponsibility &R);
 
 private:
   GenericLLVMIRPlatformSupport &PS;
   StringRef InitFunctionPrefix;
   StringRef DeInitFunctionPrefix;
 };
 
 /// Generic IR Platform Support
 ///
 /// Scrapes llvm.global_ctors and llvm.global_dtors and replaces them with
 /// specially named 'init' and 'deinit'. Injects definitions / interposes for
 /// some runtime API, including __cxa_atexit, dlopen, and dlclose.
 class GenericLLVMIRPlatformSupport : public LLJIT::PlatformSupport {
 public:
   GenericLLVMIRPlatformSupport(LLJIT &J)
       : J(J), InitFunctionPrefix(J.mangle("__orc_init_func.")),
         DeInitFunctionPrefix(J.mangle("__orc_deinit_func.")) {
 
     getExecutionSession().setPlatform(
         std::make_unique<GenericLLVMIRPlatform>(*this));
 
     setInitTransform(J, GlobalCtorDtorScraper(*this, InitFunctionPrefix,
                                               DeInitFunctionPrefix));
 
     SymbolMap StdInterposes;
 
     StdInterposes[J.mangleAndIntern("__lljit.platform_support_instance")] =
         JITEvaluatedSymbol(pointerToJITTargetAddress(this),
                            JITSymbolFlags::Exported);
     StdInterposes[J.mangleAndIntern("__lljit.cxa_atexit_helper")] =
         JITEvaluatedSymbol(pointerToJITTargetAddress(registerAtExitHelper),
                            JITSymbolFlags());
 
+   
+
     cantFail(
         J.getMainJITDylib().define(absoluteSymbols(std::move(StdInterposes))));
     cantFail(setupJITDylib(J.getMainJITDylib()));
     cantFail(J.addIRModule(J.getMainJITDylib(), createPlatformRuntimeModule()));
   }
 
   ExecutionSession &getExecutionSession() { return J.getExecutionSession(); }
 
   /// Adds a module that defines the __dso_handle global.
   Error setupJITDylib(JITDylib &JD) {
 
     // Add per-jitdylib standard interposes.
     SymbolMap PerJDInterposes;
     PerJDInterposes[J.mangleAndIntern("__lljit.run_atexits_helper")] =
         JITEvaluatedSymbol(pointerToJITTargetAddress(runAtExitsHelper),
                            JITSymbolFlags());
     cantFail(JD.define(absoluteSymbols(std::move(PerJDInterposes))));
 
     auto Ctx = std::make_unique<LLVMContext>();
     auto M = std::make_unique<Module>("__standard_lib", *Ctx);
     M->setDataLayout(J.getDataLayout());
 
     auto *Int64Ty = Type::getInt64Ty(*Ctx);
     auto *DSOHandle = new GlobalVariable(
         *M, Int64Ty, true, GlobalValue::ExternalLinkage,
         ConstantInt::get(Int64Ty, reinterpret_cast<uintptr_t>(&JD)),
         "__dso_handle");
     DSOHandle->setVisibility(GlobalValue::DefaultVisibility);
     DSOHandle->setInitializer(
         ConstantInt::get(Int64Ty, pointerToJITTargetAddress(&JD)));
 
     auto *GenericIRPlatformSupportTy =
         StructType::create(*Ctx, "lljit.GenericLLJITIRPlatformSupport");
 
     auto *PlatformInstanceDecl = new GlobalVariable(
         *M, GenericIRPlatformSupportTy, true, GlobalValue::ExternalLinkage,
         nullptr, "__lljit.platform_support_instance");
 
     auto *VoidTy = Type::getVoidTy(*Ctx);
     addHelperAndWrapper(
         *M, "__lljit_run_atexits", FunctionType::get(VoidTy, {}, false),
         GlobalValue::HiddenVisibility, "__lljit.run_atexits_helper",
         {PlatformInstanceDecl, DSOHandle});
 
     return J.addIRModule(JD, ThreadSafeModule(std::move(M), std::move(Ctx)));
   }
 
   Error notifyAdding(ResourceTracker &RT, const MaterializationUnit &MU) {
     auto &JD = RT.getJITDylib();
     if (auto &InitSym = MU.getInitializerSymbol())
       InitSymbols[&JD].add(InitSym, SymbolLookupFlags::WeaklyReferencedSymbol);
     else {
       // If there's no identified init symbol attached, but there is a symbol
       // with the GenericIRPlatform::InitFunctionPrefix, then treat that as
       // an init function. Add the symbol to both the InitSymbols map (which
       // will trigger a lookup to materialize the module) and the InitFunctions
       // map (which holds the names of the symbols to execute).
       for (auto &KV : MU.getSymbols())
         if ((*KV.first).startswith(InitFunctionPrefix)) {
           InitSymbols[&JD].add(KV.first,
                                SymbolLookupFlags::WeaklyReferencedSymbol);
           InitFunctions[&JD].add(KV.first);
         } else if ((*KV.first).startswith(DeInitFunctionPrefix)) {
           DeInitFunctions[&JD].add(KV.first);
         }
     }
     return Error::success();
   }
 
   Error initialize(JITDylib &JD) override {
     LLVM_DEBUG({
       dbgs() << "GenericLLVMIRPlatformSupport getting initializers to run\n";
     });
     if (auto Initializers = getInitializers(JD)) {
       LLVM_DEBUG(
           { dbgs() << "GenericLLVMIRPlatformSupport running initializers\n"; });
       for (auto InitFnAddr : *Initializers) {
         LLVM_DEBUG({
           dbgs() << "  Running init " << formatv("{0:x16}", InitFnAddr)
                  << "...\n";
         });
         auto *InitFn = jitTargetAddressToFunction<void (*)()>(InitFnAddr);
         InitFn();
       }
     } else
       return Initializers.takeError();
     return Error::success();
   }
 
   Error deinitialize(JITDylib &JD) override {
     LLVM_DEBUG({
       dbgs() << "GenericLLVMIRPlatformSupport getting deinitializers to run\n";
     });
     if (auto Deinitializers = getDeinitializers(JD)) {
       LLVM_DEBUG({
         dbgs() << "GenericLLVMIRPlatformSupport running deinitializers\n";
       });
       for (auto DeinitFnAddr : *Deinitializers) {
         LLVM_DEBUG({
           dbgs() << "  Running deinit " << formatv("{0:x16}", DeinitFnAddr)
                  << "...\n";
         });
         auto *DeinitFn = jitTargetAddressToFunction<void (*)()>(DeinitFnAddr);
         DeinitFn();
       }
     } else
       return Deinitializers.takeError();
 
     return Error::success();
   }
 
   void registerInitFunc(JITDylib &JD, SymbolStringPtr InitName) {
     getExecutionSession().runSessionLocked([&]() {
         InitFunctions[&JD].add(InitName);
       });
   }
 
   void registerDeInitFunc(JITDylib &JD, SymbolStringPtr DeInitName) {
     getExecutionSession().runSessionLocked(
         [&]() { DeInitFunctions[&JD].add(DeInitName); });
   }
 
 private:
 
   Expected<std::vector<JITTargetAddress>> getInitializers(JITDylib &JD) {
     if (auto Err = issueInitLookups(JD))
       return std::move(Err);
 
     DenseMap<JITDylib *, SymbolLookupSet> LookupSymbols;
     std::vector<JITDylibSP> DFSLinkOrder;
 
     if (auto Err = getExecutionSession().runSessionLocked([&]() -> Error {
           if (auto DFSLinkOrderOrErr = JD.getDFSLinkOrder())
             DFSLinkOrder = std::move(*DFSLinkOrderOrErr);
           else
             return DFSLinkOrderOrErr.takeError();
 
           for (auto &NextJD : DFSLinkOrder) {
             auto IFItr = InitFunctions.find(NextJD.get());
             if (IFItr != InitFunctions.end()) {
               LookupSymbols[NextJD.get()] = std::move(IFItr->second);
               InitFunctions.erase(IFItr);
             }
           }
           return Error::success();
         }))
       return std::move(Err);
 
     LLVM_DEBUG({
       dbgs() << "JITDylib init order is [ ";
       for (auto &JD : llvm::reverse(DFSLinkOrder))
         dbgs() << "\"" << JD->getName() << "\" ";
       dbgs() << "]\n";
       dbgs() << "Looking up init functions:\n";
       for (auto &KV : LookupSymbols)
         dbgs() << "  \"" << KV.first->getName() << "\": " << KV.second << "\n";
     });
 
     auto &ES = getExecutionSession();
     auto LookupResult = Platform::lookupInitSymbols(ES, LookupSymbols);
 
     if (!LookupResult)
       return LookupResult.takeError();
 
     std::vector<JITTargetAddress> Initializers;
     while (!DFSLinkOrder.empty()) {
       auto &NextJD = *DFSLinkOrder.back();
       DFSLinkOrder.pop_back();
       auto InitsItr = LookupResult->find(&NextJD);
       if (InitsItr == LookupResult->end())
         continue;
       for (auto &KV : InitsItr->second)
         Initializers.push_back(KV.second.getAddress());
     }
 
     return Initializers;
   }
 
   Expected<std::vector<JITTargetAddress>> getDeinitializers(JITDylib &JD) {
     auto &ES = getExecutionSession();
 
     auto LLJITRunAtExits = J.mangleAndIntern("__lljit_run_atexits");
 
     DenseMap<JITDylib *, SymbolLookupSet> LookupSymbols;
     std::vector<JITDylibSP> DFSLinkOrder;
 
     if (auto Err = ES.runSessionLocked([&]() -> Error {
           if (auto DFSLinkOrderOrErr = JD.getDFSLinkOrder())
             DFSLinkOrder = std::move(*DFSLinkOrderOrErr);
           else
             return DFSLinkOrderOrErr.takeError();
 
           for (auto &NextJD : DFSLinkOrder) {
             auto &JDLookupSymbols = LookupSymbols[NextJD.get()];
             auto DIFItr = DeInitFunctions.find(NextJD.get());
             if (DIFItr != DeInitFunctions.end()) {
               LookupSymbols[NextJD.get()] = std::move(DIFItr->second);
               DeInitFunctions.erase(DIFItr);
             }
             JDLookupSymbols.add(LLJITRunAtExits,
                                 SymbolLookupFlags::WeaklyReferencedSymbol);
           }
           return Error::success();
         }))
       return std::move(Err);
 
     LLVM_DEBUG({
       dbgs() << "JITDylib deinit order is [ ";
       for (auto &JD : DFSLinkOrder)
         dbgs() << "\"" << JD->getName() << "\" ";
       dbgs() << "]\n";
       dbgs() << "Looking up deinit functions:\n";
       for (auto &KV : LookupSymbols)
         dbgs() << "  \"" << KV.first->getName() << "\": " << KV.second << "\n";
     });
 
     auto LookupResult = Platform::lookupInitSymbols(ES, LookupSymbols);
 
     if (!LookupResult)
       return LookupResult.takeError();
 
     std::vector<JITTargetAddress> DeInitializers;
     for (auto &NextJD : DFSLinkOrder) {
       auto DeInitsItr = LookupResult->find(NextJD.get());
       assert(DeInitsItr != LookupResult->end() &&
              "Every JD should have at least __lljit_run_atexits");
 
       auto RunAtExitsItr = DeInitsItr->second.find(LLJITRunAtExits);
       if (RunAtExitsItr != DeInitsItr->second.end())
         DeInitializers.push_back(RunAtExitsItr->second.getAddress());
 
       for (auto &KV : DeInitsItr->second)
         if (KV.first != LLJITRunAtExits)
           DeInitializers.push_back(KV.second.getAddress());
     }
 
     return DeInitializers;
   }
 
   /// Issue lookups for all init symbols required to initialize JD (and any
   /// JITDylibs that it depends on).
   Error issueInitLookups(JITDylib &JD) {
     DenseMap<JITDylib *, SymbolLookupSet> RequiredInitSymbols;
     std::vector<JITDylibSP> DFSLinkOrder;
 
     if (auto Err = getExecutionSession().runSessionLocked([&]() -> Error {
           if (auto DFSLinkOrderOrErr = JD.getDFSLinkOrder())
             DFSLinkOrder = std::move(*DFSLinkOrderOrErr);
           else
             return DFSLinkOrderOrErr.takeError();
 
           for (auto &NextJD : DFSLinkOrder) {
             auto ISItr = InitSymbols.find(NextJD.get());
             if (ISItr != InitSymbols.end()) {
               RequiredInitSymbols[NextJD.get()] = std::move(ISItr->second);
               InitSymbols.erase(ISItr);
             }
           }
           return Error::success();
         }))
       return Err;
 
     return Platform::lookupInitSymbols(getExecutionSession(),
                                        RequiredInitSymbols)
         .takeError();
   }
 
   static void registerAtExitHelper(void *Self, void (*F)(void *), void *Ctx,
                                    void *DSOHandle) {
     LLVM_DEBUG({
       dbgs() << "Registering atexit function " << (void *)F << " for JD "
              << (*static_cast<JITDylib **>(DSOHandle))->getName() << "\n";
     });
     static_cast<GenericLLVMIRPlatformSupport *>(Self)->AtExitMgr.registerAtExit(
         F, Ctx, DSOHandle);
   }
 
   static void runAtExitsHelper(void *Self, void *DSOHandle) {
     LLVM_DEBUG({
       dbgs() << "Running atexit functions for JD "
              << (*static_cast<JITDylib **>(DSOHandle))->getName() << "\n";
     });
     static_cast<GenericLLVMIRPlatformSupport *>(Self)->AtExitMgr.runAtExits(
         DSOHandle);
   }
 
   // Constructs an LLVM IR module containing platform runtime globals,
   // functions, and interposes.
   ThreadSafeModule createPlatformRuntimeModule() {
     auto Ctx = std::make_unique<LLVMContext>();
     auto M = std::make_unique<Module>("__standard_lib", *Ctx);
     M->setDataLayout(J.getDataLayout());
 
     auto *GenericIRPlatformSupportTy =
         StructType::create(*Ctx, "lljit.GenericLLJITIRPlatformSupport");
 
     auto *PlatformInstanceDecl = new GlobalVariable(
         *M, GenericIRPlatformSupportTy, true, GlobalValue::ExternalLinkage,
         nullptr, "__lljit.platform_support_instance");
 
     auto *Int8Ty = Type::getInt8Ty(*Ctx);
     auto *IntTy = Type::getIntNTy(*Ctx, sizeof(int) * CHAR_BIT);
     auto *VoidTy = Type::getVoidTy(*Ctx);
     auto *BytePtrTy = PointerType::getUnqual(Int8Ty);
     auto *AtExitCallbackTy = FunctionType::get(VoidTy, {BytePtrTy}, false);
     auto *AtExitCallbackPtrTy = PointerType::getUnqual(AtExitCallbackTy);
 
-    addHelperAndWrapper(
+    /*addHelperAndWrapper(
         *M, "__cxa_atexit",
         FunctionType::get(IntTy, {AtExitCallbackPtrTy, BytePtrTy, BytePtrTy},
                           false),
         GlobalValue::DefaultVisibility, "__lljit.cxa_atexit_helper",
-        {PlatformInstanceDecl});
+        {PlatformInstanceDecl});*/
+
+    addHelperAndWrapper(
+        *M, "atexit",
+        FunctionType::get(IntTy, { AtExitCallbackPtrTy },
+            false),
+        GlobalValue::DefaultVisibility, "__lljit.cxa_atexit_helper2",
+        { PlatformInstanceDecl });
 
     return ThreadSafeModule(std::move(M), std::move(Ctx));
   }
 
   LLJIT &J;
   std::string InitFunctionPrefix;
   std::string DeInitFunctionPrefix;
   DenseMap<JITDylib *, SymbolLookupSet> InitSymbols;
   DenseMap<JITDylib *, SymbolLookupSet> InitFunctions;
   DenseMap<JITDylib *, SymbolLookupSet> DeInitFunctions;
   ItaniumCXAAtExitSupport AtExitMgr;
 };
 
 Error GenericLLVMIRPlatform::setupJITDylib(JITDylib &JD) {
   return S.setupJITDylib(JD);
 }
 
 Error GenericLLVMIRPlatform::teardownJITDylib(JITDylib &JD) {
   return Error::success();
 }
 
 Error GenericLLVMIRPlatform::notifyAdding(ResourceTracker &RT,
                                           const MaterializationUnit &MU) {
   return S.notifyAdding(RT, MU);
 }
 
 Expected<ThreadSafeModule>
 GlobalCtorDtorScraper::operator()(ThreadSafeModule TSM,
                                   MaterializationResponsibility &R) {
   auto Err = TSM.withModuleDo([&](Module &M) -> Error {
     auto &Ctx = M.getContext();
     auto *GlobalCtors = M.getNamedGlobal("llvm.global_ctors");
     auto *GlobalDtors = M.getNamedGlobal("llvm.global_dtors");
 
     auto RegisterCOrDtors = [&](GlobalVariable *GlobalCOrDtors,
                                 bool isCtor) -> Error {
       // If there's no llvm.global_c/dtor or it's just a decl then skip.
       if (!GlobalCOrDtors || GlobalCOrDtors->isDeclaration())
         return Error::success();
       std::string InitOrDeInitFunctionName;
       if (isCtor)
         raw_string_ostream(InitOrDeInitFunctionName)
             << InitFunctionPrefix << M.getModuleIdentifier();
       else
         raw_string_ostream(InitOrDeInitFunctionName)
             << DeInitFunctionPrefix << M.getModuleIdentifier();
 
       MangleAndInterner Mangle(PS.getExecutionSession(), M.getDataLayout());
       auto InternedInitOrDeInitName = Mangle(InitOrDeInitFunctionName);
       if (auto Err = R.defineMaterializing(
               {{InternedInitOrDeInitName, JITSymbolFlags::Callable}}))
         return Err;
 
       auto *InitOrDeInitFunc = Function::Create(
           FunctionType::get(Type::getVoidTy(Ctx), {}, false),
           GlobalValue::ExternalLinkage, InitOrDeInitFunctionName, &M);
       InitOrDeInitFunc->setVisibility(GlobalValue::HiddenVisibility);
       std::vector<std::pair<Function *, unsigned>> InitsOrDeInits;
       auto COrDtors = isCtor ? getConstructors(M) : getDestructors(M);
 
       for (auto E : COrDtors)
         InitsOrDeInits.push_back(std::make_pair(E.Func, E.Priority));
       llvm::sort(InitsOrDeInits,
                  [](const std::pair<Function *, unsigned> &LHS,
                     const std::pair<Function *, unsigned> &RHS) {
                    return LHS.first < RHS.first;
                  });
 
       auto *InitOrDeInitFuncEntryBlock =
           BasicBlock::Create(Ctx, "entry", InitOrDeInitFunc);
       IRBuilder<> IB(InitOrDeInitFuncEntryBlock);
       for (auto &KV : InitsOrDeInits)
         IB.CreateCall(KV.first);
       IB.CreateRetVoid();
 
       if (isCtor)
         PS.registerInitFunc(R.getTargetJITDylib(), InternedInitOrDeInitName);
       else
         PS.registerDeInitFunc(R.getTargetJITDylib(), InternedInitOrDeInitName);
 
       GlobalCOrDtors->eraseFromParent();
       return Error::success();
     };
 
     if (auto Err = RegisterCOrDtors(GlobalCtors, true))
       return Err;
     if (auto Err = RegisterCOrDtors(GlobalDtors, false))
       return Err;
 
     return Error::success();
   });
 
   if (Err)
     return std::move(Err);
 
   return std::move(TSM);
 }
 
 /// Inactive Platform Support
 ///
 /// Explicitly disables platform support. JITDylibs are not scanned for special
 /// init/deinit symbols. No runtime API interposes are injected.
 class InactivePlatformSupport : public LLJIT::PlatformSupport {
 public:
   InactivePlatformSupport() = default;
 
   Error initialize(JITDylib &JD) override {
     LLVM_DEBUG(dbgs() << "InactivePlatformSupport: no initializers running for "
                       << JD.getName() << "\n");
     return Error::success();
   }
 
   Error deinitialize(JITDylib &JD) override {
     LLVM_DEBUG(
         dbgs() << "InactivePlatformSupport: no deinitializers running for "
                << JD.getName() << "\n");
     return Error::success();
   }
 };
 
 } // end anonymous namespace
 
 namespace llvm {
 namespace orc {
 
 void LLJIT::PlatformSupport::setInitTransform(
     LLJIT &J, IRTransformLayer::TransformFunction T) {
   J.InitHelperTransformLayer->setTransform(std::move(T));
 }
 
 LLJIT::PlatformSupport::~PlatformSupport() = default;
 
 Error LLJITBuilderState::prepareForConstruction() {
 
   LLVM_DEBUG(dbgs() << "Preparing to create LLJIT instance...\n");
 
   if (!JTMB) {
     LLVM_DEBUG({
       dbgs() << "  No explicitly set JITTargetMachineBuilder. "
                 "Detecting host...\n";
     });
     if (auto JTMBOrErr = JITTargetMachineBuilder::detectHost())
       JTMB = std::move(*JTMBOrErr);
     else
       return JTMBOrErr.takeError();
   }
 
   LLVM_DEBUG({
     dbgs() << "  JITTargetMachineBuilder is "
            << JITTargetMachineBuilderPrinter(*JTMB, "  ")
            << "  Pre-constructed ExecutionSession: " << (ES ? "Yes" : "No")
            << "\n"
            << "  DataLayout: ";
     if (DL)
       dbgs() << DL->getStringRepresentation() << "\n";
     else
       dbgs() << "None (will be created by JITTargetMachineBuilder)\n";
 
     dbgs() << "  Custom object-linking-layer creator: "
            << (CreateObjectLinkingLayer ? "Yes" : "No") << "\n"
            << "  Custom compile-function creator: "
            << (CreateCompileFunction ? "Yes" : "No") << "\n"
            << "  Custom platform-setup function: "
            << (SetUpPlatform ? "Yes" : "No") << "\n"
            << "  Number of compile threads: " << NumCompileThreads;
     if (!NumCompileThreads)
       dbgs() << " (code will be compiled on the execution thread)\n";
     else
       dbgs() << "\n";
   });
 
   // If neither ES nor EPC has been set then create an EPC instance.
   if (!ES && !EPC) {
     LLVM_DEBUG({
       dbgs() << "ExecutorProcessControl not specified, "
                 "Creating SelfExecutorProcessControl instance\n";
     });
     if (auto EPCOrErr = SelfExecutorProcessControl::Create())
       EPC = std::move(*EPCOrErr);
     else
       return EPCOrErr.takeError();
   } else
     LLVM_DEBUG({
       dbgs() << "Using explicitly specified ExecutorProcessControl instance "
              << EPC.get() << "\n";
     });
 
   // If the client didn't configure any linker options then auto-configure the
   // JIT linker.
   if (!CreateObjectLinkingLayer) {
     auto &TT = JTMB->getTargetTriple();
     if (TT.isOSBinFormatMachO() &&
         (TT.getArch() == Triple::aarch64 || TT.getArch() == Triple::x86_64)) {
 
       JTMB->setRelocationModel(Reloc::PIC_);
       JTMB->setCodeModel(CodeModel::Small);
       CreateObjectLinkingLayer =
           [](ExecutionSession &ES,
              const Triple &) -> Expected<std::unique_ptr<ObjectLayer>> {
         auto ObjLinkingLayer = std::make_unique<ObjectLinkingLayer>(ES);
         ObjLinkingLayer->addPlugin(std::make_unique<EHFrameRegistrationPlugin>(
             ES, std::make_unique<jitlink::InProcessEHFrameRegistrar>()));
         return std::move(ObjLinkingLayer);
       };
     }
   }
 
   return Error::success();
 }
 
 LLJIT::~LLJIT() {
   if (CompileThreads)
     CompileThreads->wait();
   if (auto Err = ES->endSession())
     ES->reportError(std::move(Err));
 }
 
 Error LLJIT::addIRModule(ResourceTrackerSP RT, ThreadSafeModule TSM) {
   assert(TSM && "Can not add null module");
 
   if (auto Err =
           TSM.withModuleDo([&](Module &M) { return applyDataLayout(M); }))
     return Err;
 
   return InitHelperTransformLayer->add(std::move(RT), std::move(TSM));
 }
 
 Error LLJIT::addIRModule(JITDylib &JD, ThreadSafeModule TSM) {
   return addIRModule(JD.getDefaultResourceTracker(), std::move(TSM));
 }
 
 Error LLJIT::addObjectFile(ResourceTrackerSP RT,
                            std::unique_ptr<MemoryBuffer> Obj) {
   assert(Obj && "Can not add null object");
 
   return ObjTransformLayer->add(std::move(RT), std::move(Obj));
 }
 
 Error LLJIT::addObjectFile(JITDylib &JD, std::unique_ptr<MemoryBuffer> Obj) {
   return addObjectFile(JD.getDefaultResourceTracker(), std::move(Obj));
 }
 
 Expected<JITEvaluatedSymbol> LLJIT::lookupLinkerMangled(JITDylib &JD,
                                                         SymbolStringPtr Name) {
   return ES->lookup(
       makeJITDylibSearchOrder(&JD, JITDylibLookupFlags::MatchAllSymbols), Name);
 }
 
 Expected<std::unique_ptr<ObjectLayer>>
 LLJIT::createObjectLinkingLayer(LLJITBuilderState &S, ExecutionSession &ES) {
 
   // If the config state provided an ObjectLinkingLayer factory then use it.
   if (S.CreateObjectLinkingLayer)
     return S.CreateObjectLinkingLayer(ES, S.JTMB->getTargetTriple());
 
   // Otherwise default to creating an RTDyldObjectLinkingLayer that constructs
   // a new SectionMemoryManager for each object.
   auto GetMemMgr = []() { return std::make_unique<SectionMemoryManager>(); };
   auto Layer =
       std::make_unique<RTDyldObjectLinkingLayer>(ES, std::move(GetMemMgr));
 
   if (S.JTMB->getTargetTriple().isOSBinFormatCOFF()) {
     Layer->setOverrideObjectFlagsWithResponsibilityFlags(true);
     Layer->setAutoClaimResponsibilityForObjectSymbols(true);
   }
 
   // FIXME: Explicit conversion to std::unique_ptr<ObjectLayer> added to silence
   //        errors from some GCC / libstdc++ bots. Remove this conversion (i.e.
   //        just return ObjLinkingLayer) once those bots are upgraded.
   return std::unique_ptr<ObjectLayer>(std::move(Layer));
 }
 
 Expected<std::unique_ptr<IRCompileLayer::IRCompiler>>
 LLJIT::createCompileFunction(LLJITBuilderState &S,
                              JITTargetMachineBuilder JTMB) {
 
   /// If there is a custom compile function creator set then use it.
   if (S.CreateCompileFunction)
     return S.CreateCompileFunction(std::move(JTMB));
 
   // Otherwise default to creating a SimpleCompiler, or ConcurrentIRCompiler,
   // depending on the number of threads requested.
   if (S.NumCompileThreads > 0)
     return std::make_unique<ConcurrentIRCompiler>(std::move(JTMB));
 
   auto TM = JTMB.createTargetMachine();
   if (!TM)
     return TM.takeError();
 
   return std::make_unique<TMOwningSimpleCompiler>(std::move(*TM));
 }
 
 LLJIT::LLJIT(LLJITBuilderState &S, Error &Err)
     : DL(""), TT(S.JTMB->getTargetTriple()) {
 
   ErrorAsOutParameter _(&Err);
 
   assert(!(S.EPC && S.ES) && "EPC and ES should not both be set");
 
   if (S.EPC) {
     ES = std::make_unique<ExecutionSession>(std::move(S.EPC));
   } else if (S.ES)
     ES = std::move(S.ES);
   else {
     if (auto EPC = SelfExecutorProcessControl::Create()) {
       ES = std::make_unique<ExecutionSession>(std::move(*EPC));
     } else {
       Err = EPC.takeError();
       return;
     }
   }
 
   if (auto MainOrErr = this->ES->createJITDylib("main"))
     Main = &*MainOrErr;
   else {
     Err = MainOrErr.takeError();
     return;
   }
 
   if (S.DL)
     DL = std::move(*S.DL);
   else if (auto DLOrErr = S.JTMB->getDefaultDataLayoutForTarget())
     DL = std::move(*DLOrErr);
   else {
     Err = DLOrErr.takeError();
     return;
   }
 
   auto ObjLayer = createObjectLinkingLayer(S, *ES);
   if (!ObjLayer) {
     Err = ObjLayer.takeError();
     return;
   }
   ObjLinkingLayer = std::move(*ObjLayer);
   ObjTransformLayer =
       std::make_unique<ObjectTransformLayer>(*ES, *ObjLinkingLayer);
 
   {
     auto CompileFunction = createCompileFunction(S, std::move(*S.JTMB));
     if (!CompileFunction) {
       Err = CompileFunction.takeError();
       return;
     }
     CompileLayer = std::make_unique<IRCompileLayer>(
         *ES, *ObjTransformLayer, std::move(*CompileFunction));
     TransformLayer = std::make_unique<IRTransformLayer>(*ES, *CompileLayer);
     InitHelperTransformLayer =
         std::make_unique<IRTransformLayer>(*ES, *TransformLayer);
   }
 
   if (S.NumCompileThreads > 0) {
     InitHelperTransformLayer->setCloneToNewContextOnEmit(true);
     CompileThreads =
         std::make_unique<ThreadPool>(hardware_concurrency(S.NumCompileThreads));
     ES->setDispatchTask([this](std::unique_ptr<Task> T) {
       // FIXME: We should be able to use move-capture here, but ThreadPool's
       // AsyncTaskTys are std::functions rather than unique_functions
       // (because MSVC's std::packaged_tasks don't support move-only types).
       // Fix this when all the above gets sorted out.
       CompileThreads->async([UnownedT = T.release()]() mutable {
         std::unique_ptr<Task> T(UnownedT);
         T->run();
       });
     });
   }
 
   if (S.SetUpPlatform)
     Err = S.SetUpPlatform(*this);
   else
     setUpGenericLLVMIRPlatform(*this);
 }
 
 std::string LLJIT::mangle(StringRef UnmangledName) const {
   std::string MangledName;
   {
     raw_string_ostream MangledNameStream(MangledName);
     Mangler::getNameWithPrefix(MangledNameStream, UnmangledName, DL);
   }
   return MangledName;
 }
 
 Error LLJIT::applyDataLayout(Module &M) {
   if (M.getDataLayout().isDefault())
     M.setDataLayout(DL);
 
   if (M.getDataLayout() != DL)
     return make_error<StringError>(
         "Added modules have incompatible data layouts: " +
             M.getDataLayout().getStringRepresentation() + " (module) vs " +
             DL.getStringRepresentation() + " (jit)",
         inconvertibleErrorCode());
 
   return Error::success();
 }
 
 void setUpGenericLLVMIRPlatform(LLJIT &J) {
   LLVM_DEBUG(
       { dbgs() << "Setting up GenericLLVMIRPlatform support for LLJIT\n"; });
   J.setPlatformSupport(std::make_unique<GenericLLVMIRPlatformSupport>(J));
 }
 
 Error setUpInactivePlatform(LLJIT &J) {
   LLVM_DEBUG(
       { dbgs() << "Explicitly deactivated platform support for LLJIT\n"; });
   J.setPlatformSupport(std::make_unique<InactivePlatformSupport>());
   return Error::success();
 }
 
 Error LLLazyJITBuilderState::prepareForConstruction() {
   if (auto Err = LLJITBuilderState::prepareForConstruction())
     return Err;
   TT = JTMB->getTargetTriple();
   return Error::success();
 }
 
 Error LLLazyJIT::addLazyIRModule(JITDylib &JD, ThreadSafeModule TSM) {
   assert(TSM && "Can not add null module");
 
   if (auto Err = TSM.withModuleDo(
           [&](Module &M) -> Error { return applyDataLayout(M); }))
     return Err;
 
   return CODLayer->add(JD, std::move(TSM));
 }
 
 LLLazyJIT::LLLazyJIT(LLLazyJITBuilderState &S, Error &Err) : LLJIT(S, Err) {
 
   // If LLJIT construction failed then bail out.
   if (Err)
     return;
 
   ErrorAsOutParameter _(&Err);
 
   /// Take/Create the lazy-compile callthrough manager.
   if (S.LCTMgr)
     LCTMgr = std::move(S.LCTMgr);
   else {
     if (auto LCTMgrOrErr = createLocalLazyCallThroughManager(
             S.TT, *ES, S.LazyCompileFailureAddr))
       LCTMgr = std::move(*LCTMgrOrErr);
     else {
       Err = LCTMgrOrErr.takeError();
       return;
     }
   }
 
   // Take/Create the indirect stubs manager builder.
   auto ISMBuilder = std::move(S.ISMBuilder);
 
   // If none was provided, try to build one.
   if (!ISMBuilder)
     ISMBuilder = createLocalIndirectStubsManagerBuilder(S.TT);
 
   // No luck. Bail out.
   if (!ISMBuilder) {
     Err = make_error<StringError>("Could not construct "
                                   "IndirectStubsManagerBuilder for target " +
                                       S.TT.str(),
                                   inconvertibleErrorCode());
     return;
   }
 
   // Create the COD layer.
   CODLayer = std::make_unique<CompileOnDemandLayer>(
       *ES, *InitHelperTransformLayer, *LCTMgr, std::move(ISMBuilder));
 
   if (S.NumCompileThreads > 0)
     CODLayer->setCloneToNewContextOnEmit(true);
 }
 
 } // End namespace orc.
 } // End namespace llvm.
